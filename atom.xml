<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://kangjn.github.io/</id>
    <title>MyBlog</title>
    <updated>2021-04-22T09:13:04.318Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://kangjn.github.io/"/>
    <link rel="self" href="https://kangjn.github.io/atom.xml"/>
    <subtitle>我的博客</subtitle>
    <logo>https://kangjn.github.io/images/avatar.png</logo>
    <icon>https://kangjn.github.io/favicon.ico</icon>
    <rights>All rights reserved 2021, MyBlog</rights>
    <entry>
        <title type="html"><![CDATA[微服务拆分]]></title>
        <id>https://kangjn.github.io/post/wei-fu-wu-chai-fen/</id>
        <link href="https://kangjn.github.io/post/wei-fu-wu-chai-fen/">
        </link>
        <updated>2021-04-22T09:04:54.000Z</updated>
        <content type="html"><![CDATA[<h3 id="一-拆分"><strong>一、拆分</strong></h3>
<p>**1、新浪微博微服务从纵横两个维度来划分，简单粗暴：</p>
<p><strong>1.1 纵向拆分</strong></p>
<p>从业务维度进行拆分。标准是按照业务的关联程度来决定，关联比较密切的业务适合拆分为一个微服务，而功能相对比较独立的业务适合单独拆分为一个微服务。</p>
<p><strong>1.2 横向拆分</strong></p>
<p>从公共且独立功能维度拆分。标准是按照是否有公共的被多个其他服务调用，且依赖的资源独立不与其他业务耦合。</p>
<p>纵向以业务为基准，关系铁的在一起；横向功能独立的在一起。</p>
<figure data-type="image" tabindex="1"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/115502.png" alt="img" loading="lazy"></figure>
<p><strong>2.1 服务拆分要迎合业务的需要</strong></p>
<p>充分考虑业务独立性和专业性，避免以团队来定义服务边界，从而出现“土匪”抢地盘，影响团队信任。</p>
<p>这个维度和上面的类似，但是强调的是业务和团队成员的各自独立性，对上面是一种很好的补充。</p>
<p><strong>2.2 拆分后的维护成本要低于拆分前</strong></p>
<p>这里的维护成本包括：人力、物力、时间。</p>
<p>这里的成本对大部分中小团队来说都是必须要考虑的重要环节，如果投入和收益不能成正比，或者超出领导的预算或者市场窗口，那么先进的技术就是绊脚石，千万不要迷恋技术，所谓工程师思维千万要不得。</p>
<p><strong>2.3 拆分不仅仅是架构的调整，组织结构上也要做响应的适应性优化</strong></p>
<p>确保拆分后的服务由相对独立的团队负责维护。</p>
<p>这句话怎么理解呢？传统的团队划分是按照产品部、前端、后端横向划分，微服务化以后的团队可能就会是吃一张披萨饼的人数，产品、前端、后端被归类到服务里面，以服务为中心来分配人数。</p>
<p>把具有不同扩展性要求的服务拆分出来，分别进行部署，降低成本，提高效率。比如全文搜索服务。</p>
<p>这点和上面的按功能独立性来拆分有点类似，功能独立其实就是面向可扩展性。</p>
<p><strong>2.5 考虑软件发布频率</strong></p>
<p>比如把20%经常变动的部分进行抽离，80%不经常变动的单独部署和管理。说白了就是按照8/2原则进行拆分。这个拆分的好处很明显，可以尽可能的减少发布产生的后遗症，比如用户体验、服务相互干扰等。</p>
<p>但是这里有一个问题，假如20%的服务分属于不同的业务层面，那该怎么办？所以这里的拆分应该有个优先级，在拆分相互冲突的时候应该要优先考虑权重比较高的那个。</p>
<figure data-type="image" tabindex="2"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/303502.png" alt="img" loading="lazy"></figure>
<p>**3、另一种拆分：</p>
<p><strong>3.1 基于业务逻辑</strong></p>
<p>将系统中的业务按照职责范围进行识别，职责相同的划分为一个单独的服务。这种业务优先的方式在前面两种姿势当中都出现过，可见是最基本，最重要的划分方式（没有之一）。</p>
<p><strong>3.2 基于稳定性</strong></p>
<p>将系统中的业务模块按照稳定性进行排序。稳定的、不经常修改的划分一块；将不稳定的，经常修改的划分为一个独立服务。比如日志服务、监控服务都是相对稳定的服务，可以归到一起。这个很类似上面提到的2/8原则，80%的业务是稳定的。</p>
<p>至此你会发现服务的拆分真的没有绝对的标准，只有合理才是标准。</p>
<p><strong>3.3 基于可靠性</strong></p>
<p>同样，将系统中的业务模块按照可靠性进行排序。对可靠性要求比较高的核心模块归在一起，对可靠性要求不高的非核心模块归在一块。</p>
<p>这种拆分的高明可以很好的规避因为一颗老鼠屎坏了一锅粥的单体弊端，同时将来要做高可用方案也能很好的节省机器或带宽的成本。</p>
<p><strong>3.4 基于高性能</strong></p>
<p>同上，将系统中的业务模块按照对性能的要求进行优先级排序。把对性能要求较高的模块独立成一个服务，对性能要求不高的放在一起。比如全文搜索，商品查询和分类，秒杀就属于高性能的核心模块。</p>
<figure data-type="image" tabindex="3"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/457502.png" alt="img" loading="lazy"></figure>
<p><strong>4、盘点</strong></p>
<p>以上不同拆分各有千秋，异曲同工！</p>
<ul>
<li>对业务逻辑均不约而同的放在第一位。</li>
<li>对业务模块的稳定性和可靠性，对功能的独立性、可扩展性都有相似的看法</li>
<li>强调拆分应该是多选，而不是单选。具体情况具体分析，可以自由灵活排列组合。</li>
</ul>
<h3 id="二-题外话">**二、题外话</h3>
<p>如果你把上面的划分角度背下来了拿去现场套，可能还会遇到矛盾或争议。</p>
<p><strong>1、业务矛盾</strong></p>
<p>假如我们按照业务来划分，根据粒度大小，可能存在以下两种：</p>
<ul>
<li>第一种分为商品、交易、用户3个服务；</li>
<li>第二种分为商品、订单、支付、物流、买家、卖家6个服务。</li>
</ul>
<p>3 VS 6，这该怎么办？</p>
<p>如果你的团队只有9个人，那么分成3个是合理的，如果有18个人，那么6个服务是合理的。这里引入团队成员进行协助拆分。</p>
<p>可见拆分的姿势不是单选，而是多选的。这个时候必须要考虑团队成员数量。</p>
<p>在拆分遇到争议的时候，一般情况下我们增加一项拆分条件，虽然不是充要条件，但至少我们的答案会更加接近真理。</p>
<p>除了业务可能存在争议，其他的划分也会有争议，比如一个独立的服务到底需要多少人员的配置？</p>
<p><strong>2、三个火枪手(人员配置)</strong></p>
<p>上面提到的人员数量配置，这里为什么是9和18呢？(这里的团队配置参考李云华前辈提到的三个火枪手的观点)</p>
<p>换一种问法，为什么说是三个人分配一个服务（当然，成员主要是后端人员）？</p>
<ul>
<li>假设是1个人，请个假、生个病都不行。一个人会遇到单点的问题，所以不合理。</li>
<li>假设是2个人，终于有备份了，但是抽离一个后，剩下1个压力还是很大，不合理。</li>
<li>假设是3个人，抽离一个还有2个在。而且数字3是个稳定而神奇数字，用得好事半功倍。特别是遇到技术讨论，3个人相对周全，如果是2个可能会各持己见，带有自我的偏见和盲区。</li>
</ul>
<p>那么这个3是不是就是稳定的数量呢？</p>
<p>假设你做的是边开飞机边换引擎的重写工作，那么前期3个人都可能捉襟见肘。但是到了服务后期，你可能1个就够了。</p>
<p>所以3在我的理解应该是一个基准线，不同的时间段会有上下波动，但是相对稳定。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[一份微服务架构手稿图]]></title>
        <id>https://kangjn.github.io/post/yi-fen-wei-fu-wu-jia-gou-shou-gao-tu/</id>
        <link href="https://kangjn.github.io/post/yi-fen-wei-fu-wu-jia-gou-shou-gao-tu/">
        </link>
        <updated>2021-04-22T08:26:56.000Z</updated>
        <content type="html"><![CDATA[<p>什么是微服务？</p>
<p>微服务 Microservices 之父，马丁.福勒，对微服务大概的概述如下：</p>
<p>就目前而言，对于微服务业界并没有一个统一的、标准的定义（While there is no precise definition of this architectural style ) 。</p>
<p>但通常在其而言，微服务架构是一种架构模式或者说是一种架构风格，它提倡将单一应用程序划分成一组小的服务，每个服务运行独立的自己的进程中，服务之间互相协调、互相配合，为用户提供最终价值。</p>
<p>服务之间采用轻量级的通信机制互相沟通（通常是基于 HTTP 的 RESTful API ) 。每个服务都围绕着具体业务进行构建，并且能够被独立地部署到生产环境、类生产环境等。</p>
<p>另外，应尽量避免统一的、集中式的服务管理机制，对具体的一个服务而言，应根据业务上下文，选择合适的语言、工具对其进行构建，可以有一个非常轻量级的集中式管理来协调这些服务。可以使用不同的语言来编写服务，也可以使用不同的数据存储。</p>
<p>根据马丁.福勒的描述，我总结了以下几点：</p>
<figure data-type="image" tabindex="1"><a href="http://img.javastack.cn/1590629991746502.png"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/746502.png" alt="img" loading="lazy"></a></figure>
<p><strong>①小服务</strong></p>
<p>小服务，没有特定的标准或者规范，但他在总体规范上一定是小的。</p>
<p><strong>②进程独立</strong></p>
<p>每一组服务都是独立运行的，可能我这个服务运行在 Tomcat 容器，而另一个服务运行在 Jetty 上。可以通过进程方式，不断的横向扩展整个服务。</p>
<p><strong>③通信</strong></p>
<p>过去的协议都是很重的，就像 ESB，就像 SOAP，轻通信，这意味着相比过去更智能更轻量的服务相互调用，就所谓 smart endpoints and dumb pipes。</p>
<p>这些 Endpoint 都是解耦的，完成一个业务通信调用串起这些 Micro Service 就像是 Linux 系统中通过管道串起一系列命令业务。</p>
<p>过去的业务，我们通常会考虑各种各样的依赖关系，考虑系统耦合带来的问题。微服务，可以让开发者更专注于业务的逻辑开发。</p>
<p><strong>④部署</strong></p>
<p>不止业务要独立，部署也要独立。不过这也意味着，传统的开发流程会出现一定程度的改变，开发的适合也要有一定的运维职责。</p>
<p><strong>⑤管理</strong></p>
<p>传统的企业级 SOA 服务往往很大，不易于管理，耦合性高，团队开发成本比较大。</p>
<p>微服务，可以让团队各思其政的选择技术实现，不同的 Service 可以根据各自的需要选择不同的技术栈来实现其业务逻辑。</p>
<h2 id="微服务的利与弊">微服务的利与弊</h2>
<p>为什么用微服务呢？因为好玩？不是的。下面是我从网络上找到说的比较全的优点：</p>
<ul>
<li>优点是每个服务足够内聚，足够小，代码容易理解这样能聚焦一个指定的业务功能或业务需求。</li>
<li>开发简单、开发效率提高，一个服务可能就是专一的只干一件事。</li>
<li>微服务能够被小团队单独开发，这个小团队是 2 到 5 人的开发人员组成。</li>
<li>微服务是松耦合的，是有功能意义的服务，无论是在开发阶段或部署阶段都是独立的。</li>
<li>微服务能使用不同的语言开发。</li>
<li>易于和第三方集成，微服务允许容易且灵活的方式集成自动部署，通过持续集成工具，如 Jenkins，Hudson，bamboo。</li>
<li>微服务易于被一个开发人员理解，修改和维护，这样小团队能够更关注自己的工作成果。无需通过合作才能体现价值。微服务允许你利用融合最新技术。</li>
<li>微服务只是业务逻辑的代码，不会和 HTML，CSS 或其他界面组件混合。</li>
<li>每个微服务都有自己的存储能力，可以有自己的数据库，也可以有统一数据库。</li>
</ul>
<p>总的来说，微服务的优势，就是在于，面对大的系统，可以有效的减少复杂程度，使服务架构的逻辑更清晰明了。</p>
<p>但是这样也会带来很多问题，就譬如分布式环境下的数据一致性，测试的复杂性，运维的复杂性。</p>
<h2 id="什么组织适合使用微服务">什么组织适合使用微服务？</h2>
<p>微服务带了种种优点，种种弊端，那么什么组织适合使用微服务？</p>
<p>①墨菲定律（设计系统）和康威定律（系统划分）<br>
康威定律，是一个五十多年前就被提出来的微服务概念。在康威的这篇文章中，最有名的一句话就是：</p>
<blockquote>
<p>Organizations which design systems are constrained to produce designs which are copies of the communication structures of these  organizations.</p>
<p>-Melvin Conway(1967)</p>
</blockquote>
<p>中文直译大概的意思就是：设计系统的组织，其产生的设计等同于组织之内、组织之间的沟通结构。</p>
<figure data-type="image" tabindex="2"><a href="http://img.javastack.cn/1590629991985502.png"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/985502.png" alt="img" loading="lazy"></a></figure>
<p>②架构演化</p>
<p>架构是不断演化出来的，微服务也是这样，当从各大科技公司，规模大到一定程度，完全需要演化成更进一步管理的技术架构体系。[淘宝千万并发，14 次架构演进]，推荐大家看下。</p>
<p>[<img src="https://gitee.com/kangjun/MyBlogImage/raw/master/233502.png" alt="img" loading="lazy">]</p>
<p>传统的团队，都是面向过程化的，产品想完了去找策划，策划完了找开发，接着顺着一步一步找。</p>
<p>我们做技术都是为了产品的，一旦过程出来了什么问题，回溯寻找问题会非常耗时。</p>
<figure data-type="image" tabindex="3"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/387502.png" alt="img" loading="lazy"></figure>
<p>使用了微服务架构体系，团队组织方式需要转变成跨职能团队，即每个团队都有产品专家，策划专家，开发专家，运维专家，他们使用 API 方式发布他们的功能，而平台使用他们的功能发布产品。</p>
<figure data-type="image" tabindex="4"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/717502.png" alt="img" loading="lazy"></figure>
<h2 id="微服务技术架构体系">微服务技术架构体系</h2>
<p>下面我分享一下大部分公司都使用的微服务技术架构体系：</p>
<figure data-type="image" tabindex="5"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/956502.png" alt="img" loading="lazy"></figure>
<h3 id="服务发现">服务发现</h3>
<p>主流的服务发现，分为三种：</p>
<p><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/87502.jpg" alt="1590629993087502" loading="lazy">第一种，开发人员开发了程序以后，会找运维配一个域名，服务的话通过 DNS 就能找到我们对应的服务。</p>
<p>缺点是，由于服务没有负载均衡功能，对负载均衡服务，可能会有相当大的性能问题。</p>
<figure data-type="image" tabindex="6"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/191502.jpg" alt="191502" loading="lazy"></figure>
<p>第二种，是目前普遍的做法。可以参考 Zuul 网关，每一个服务都通过服务端内置的功能注册到注册中心，服务消费者不断轮询注册中心发现对应的服务，使用内置负载均衡调用服务。</p>
<p>缺点是，对多语言环境不是很好，你需要单独给消费者的客户端开发服务发现和负载均衡功能。当然了，这个方法通常都是用在 Spring Cloud 上的。</p>
<figure data-type="image" tabindex="7"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/640383.jpg" alt="img" loading="lazy"></figure>
<p>第三种，是将客户端和负载均衡放在同一个主机，而不是同一个进程内。</p>
<ul>
<li>[这种方法相对第一种第二种方法来说，改善了他们的缺点，但是会极大增加运维成本。]</li>
</ul>
<h3 id="网关">[网关]</h3>
<p>微服务的网关是什么？我们可以联系生活实际想一下。每一个大的公司，都会有一偏属于自己的建筑区，而这建筑区内，都有不少的门卫。如果有外来人员进入公司，会先和门卫打好招呼，才能进去。</p>
<p>将生活实际联系到微服务上，就不难理解网关的意思了：</p>
<figure data-type="image" tabindex="8"><a href="http://img.javastack.cn/1590629993612502.png"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/640324.jpg" alt="img" loading="lazy"></a></figure>
<p>网关的作用如下：</p>
<ul>
<li>反向路由：很多时候，公司不想让外部人员看到我们公司的内部，就需要网关来进行反向路由。即将外部请求转换成内部具体服务调用。</li>
<li>安全认证：网络中会有很多恶意访问，譬如爬虫，譬如黑客攻击，网关维护安全功能。</li>
<li>限流熔断：当请求很多服务不堪重负，会让我们的服务自动关闭，导致不能用服务。限流熔断可以有效的避免这类问题。</li>
<li>日志监控：所有的外面的请求都会经过网关，这样我们就可以使用网关来记录日志信息。</li>
<li>灰度发布，蓝绿部署。是指能够平滑过渡的一种发布方式。在其上可以进行 A/B testing。即让一部分用户继续用产品特性 A，一部分用户开始用产品特性 B，如果用户对 B 没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到 B 上面来。</li>
</ul>
<p>[开源网关 Zuul 架构：]</p>
<figure data-type="image" tabindex="9"><a href="http://img.javastack.cn/1590629993902502.png"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/640321.jpg" alt="img" loading="lazy"></a></figure>
<p>Zuul 网关核心其实是一个 Servlet，所有请求都会经过 Zuul Servlet 传到 ZuulFilter Runner，然后分发到三种过滤器。</p>
<p>先说说架构图左半部分，分别是使用 Groovy 实现的前置路由过滤器，路由过滤器，后置路由过滤器。</p>
<p>一般请求都会先经过前置路由过滤器处理，一般的自定义 Java 封装逻辑也会在这里实现。</p>
<p>路由过滤器，实现的是找到对应的微服务进行调用。调用完了，响应回来，会经过后置路由过滤器，通过后置路由过滤器我们可以封装日志审计的处理。</p>
<p>可以说 Zuul 网关最大的特色就是它的三层过滤器。是 Zuul 网关设计的自定义过滤器加载机制。</p>
<p>网关内部会有生产者消费者模型，自动的将过滤器脚本发布到 Zuul 网关读取加载运行。</p>
<h3 id="配置中心">配置中心</h3>
<p>以前，开发人员把配置文件放在开发文件里面，这样会有很多隐患。譬如，配置规范不同，无法追溯配置人员。</p>
<p>一旦需要大规模改动配置，改动时间会很长，无法追溯配置人员，从而影响整个产品，后果是我们承担不起的。</p>
<p>因此就有配置中心这个喽！现在的开源中心有百度配置中心 Disconf，Spring Cloud Config，Apollo。</p>
<p>今天重点说说现在应用质量不错的配置中心，携程开源的阿波罗（Apollo）：</p>
<figure data-type="image" tabindex="10"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/781502.png" alt="img" loading="lazy"></figure>
<p>Apollo 的配置中心规模比较大，本地应用会有响应的配置中心客户端，可以定时同步配置中心里的配置。如果配置中心怠机，会使用缓存来进行配置。关注微信公众号：Java技术栈，在后台回复：架构，可以获取我整理的 N 篇最新架构干货。</p>
<h3 id="通讯方式">通讯方式</h3>
<p>关于通讯方式，一般市面也就是两种远程调用方式，我整理了一个表格：</p>
<figure data-type="image" tabindex="11"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/516502.png" alt="img" loading="lazy"></figure>
<h3 id="监控预警">监控预警</h3>
<p>监控预警对于微服务很重要，一个可靠的监控预警体系对微服务运行至关重要。</p>
<p>一般监控分为如下层次：</p>
<figure data-type="image" tabindex="12"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/744502.png" alt="img" loading="lazy"></figure>
<p>从基础设施到用户端，层层有监控，全方位，多角度，每一个层面都很重要。</p>
<p>总体来说，微服务可分为 5 个监控点：</p>
<ul>
<li>日志监控</li>
<li>Metrics 监控</li>
<li>健康检查</li>
<li>调用链检查</li>
<li>告警系统</li>
</ul>
<p><strong>①监控架构</strong></p>
<p>下面的图是大部分公司的一种监控架构图。每一个服务都有一个 Agent，Agent 收集到关键信息，会传到一些 MQ 中，为了解耦。</p>
<p>同时将日志传入 ELK，将 Metrics 传入 InfluxDB 时间序列库。而像 Nagios，可以定期向 Agent 发起信息检查微服务。关注微信公众号：Java技术栈，在后台回复：架构，可以获取我整理的 N 篇最新架构干货。</p>
<figure data-type="image" tabindex="13"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/874502.png" alt="img" loading="lazy"></figure>
<p><strong>②调用链监控 APM</strong></p>
<p>很多公司都有调用链监控，就譬如阿里有鹰眼监控，点评的 Cat，大部分调用链监控（没错，我指的 Zipkin）架构是这样的：</p>
<figure data-type="image" tabindex="14"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/055502.jpg" alt="055502" loading="lazy"></figure>
<p>当请求进入 Web 容器的时候，会经过创建 Tracer，连接 Spans（模拟潜在的分布式工作的延迟，该模块还包含在系统网络间传递跟踪上下文信息的工具包，如通过 HTTP Headers）。</p>
<p>Spans 有一个上下文，其中包含 Tracer 标识符，将其放在表示分布式操作的树的正确位置。</p>
<p>当我们把图中的各种 Span 放到后端的时候，我们的服务调用链会动态的生成调用链。</p>
<p>下面是一些市场上用的比较多的调用链监控对比：</p>
<figure data-type="image" tabindex="15"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/193502.jpg" alt="193502" loading="lazy"></figure>
<h3 id="熔断-隔离-限流-降级">熔断、隔离、限流、降级</h3>
<p>面对巨大的突发流量下，大型公司一般会采用一系列的熔断（系统自动将服务关闭防止让出现的问题最大化）、隔离（将服务和服务隔离，防止一个服务挂了其他服务不能访问）、限流（单位时间内之允许一定数量用户访问）、降级（当整个微服务架构整体的负载超出了预设的上限阈值或即将到来的流量预计将会超过预设的阈值时，为了保证重要或基本的服务能正常运行，我们可以将一些不重要或不紧急的服务或任务进行服务的延迟使用或暂停使用）措施。</p>
<p>下面介绍一下 Hystrix 的运行流程：</p>
<figure data-type="image" tabindex="16"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/492502.png" alt="img" loading="lazy"></figure>
<p>Hystrix 停止开发，Spring Cloud 何去何从？</p>
<p>每一个微服务调用时，都会使用 Hystrix 的 Command 方式（上图的左上角那个），然后使用 Command 同步的，或者是响应式的，或者是异步的，判断电路是否熔断（顺着图从左往右看），如果断路则走降级 Fallback。</p>
<p>如果这个线闭合着，但是线程资源没了，队列满了，则走限流措施（看图的第 5 步）。</p>
<p>如果走完了，执行成功了，则走 run() 方法，获取 Response，但是这个过程如果出错了，则继续走降级 Fallback。</p>
<p>同时，看图最上面有一个后缀是 Health 的，这是一个计算整个链路是否健康的组件，每一步操作都被它记录着。</p>
<h3 id="容器与服务编排引擎">容器与服务编排引擎</h3>
<p>从物理机到虚拟机，从虚拟机到容器；从物理集群到 OpenStack，OpenStack 到 Kubernetes；科技不断的变化，我们的认知也没刷新。</p>
<p>我们从容器开始说起，它首先是一个相对独立的运行环境，在这一点有点类似于虚拟机，但是不像虚拟机那样彻底。</p>
<p>虚拟机会将虚拟硬件、内核（即操作系统）以及用户空间打包在新虚拟机当中，虚拟机能够利用“虚拟机管理程序”运行在物理设备之上。</p>
<p>虚拟机依赖于 Hypervisor，其通常被安装在“裸金属”系统硬件之上，这导致 Hypervisor 在某些方面被认为是一种操作系统。</p>
<p>一旦 Hypervisor 安装完成， 就可以从系统可用计算资源当中分配虚拟机实例了，每台虚拟机都能够获得唯一的操作系统和负载（应用程序）。</p>
<p>简言之，虚拟机先需要虚拟一个物理环境，然后构建一个完整的操作系统，再搭建一层 Runtime，然后供应用程序运行。</p>
<p>对于容器环境来说，不需要安装主机操作系统，直接将容器层（比如 LXC 或 Libcontainer）安装在主机操作系统（通常是 Linux 变种）之上。</p>
<p>在安装完容器层之后，就可以从系统可用计算资源当中分配容器实例了，并且企业应用可以被部署在容器当中。</p>
<p>但是，每个容器化应用都会共享相同的操作系统(单个主机操作系统)。容器可以看成一个装好了一组特定应用的虚拟机，它直接利用了宿主机的内核，抽象层比虚拟机更少，更加轻量化，启动速度极快。</p>
<p>相比于虚拟机，容器拥有更高的资源使用效率，因为它并不需要为每个应用分配单独的操作系统——实例规模更小、创建和迁移速度也更快。这意味着相比于虚拟机，单个操作系统能够承载更多的容器。</p>
<p>云提供商十分热衷于容器技术，因为在相同的硬件设备当中，可以部署数量更多的容器实例。</p>
<p>此外，容器易于迁移，但是只能被迁移到具有兼容操作系统内核的其他服务器当中，这样就会给迁移选择带来限制。</p>
<p>因为容器不像虚拟机那样同样对内核或者虚拟硬件进行打包，所以每套容器都拥有自己的隔离化用户空间，从而使得多套容器能够运行在同一主机系统之上。</p>
<p>我们可以看到全部操作系统层级的架构都可实现跨容器共享，惟一需要独立构建的就是二进制文件与库。</p>
<p>正因为如此，容器才拥有极为出色的轻量化特性。我们最常用的容器是 Docker。</p>
<p><strong>①容器编排</strong></p>
<p>过去虚拟机可以通过云平台 OpenStack 管理虚拟化，容器时代如何管理容器呢？这就要看看容器编排引擎了。</p>
<p>Apache Mesos：Mesos 是基于 Master，Slave 架构，框架决定如何利用资源，Master 负责管理机器，Slave 会定期的将机器情况报告给 Master，Master 再将信息给框架。Master 是高可用的，因为 ZK，也有 Leader 的存在。</p>
<p>下面是架构图：</p>
<figure data-type="image" tabindex="17"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/731502.jpg" alt="731502" loading="lazy"></figure>
<p>Kubernetes：Kubernetes 是最近十分火热的开源容器编排引擎</p>
<figure data-type="image" tabindex="18"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/981502.jpg" alt="981502" loading="lazy"></figure>
<p>Kubernetes 设计理念和功能其实就是一个类似 Linux 的分层架构，先说说每一个 Kubernetes 节点内部，kubelet 管理全局全局 pod，而每一个 pod 承载着一个或多个容器，kube-proxy 负责网络代理和负载均衡。</p>
<p>Kubernetes 节点外部，则是对应的控制管理服务器，负责统一管理各个节点调度分配与运行。</p>
<p><strong>②服务网格化</strong></p>
<p>关于服务网络化，后面会更加深入的为大家进行讲解。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[微服务介绍]]></title>
        <id>https://kangjn.github.io/post/wei-fu-wu-jie-shao/</id>
        <link href="https://kangjn.github.io/post/wei-fu-wu-jie-shao/">
        </link>
        <updated>2021-04-22T08:05:18.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li>
<p><strong>微服务是什么</strong></p>
</li>
<li>
<p><strong>为什么要采用微服务</strong></p>
</li>
<li>
<p><strong>微服务架构</strong></p>
</li>
<li>
<p><strong>架构设计模式</strong></p>
</li>
<li>
<p><strong>服务拆分</strong></p>
</li>
<li>
<p><strong>微服务框架</strong></p>
</li>
<li>
<p>架构模式有很多，微服务不是唯一的选择也不是什么银弹。</p>
</li>
<li>
<p>“你必须长的足够高才能使用微服务”。微服务基础设施，尤其是容器技术、自动化部署、自动化测试这些不完备，微服务形同虚设，不会带来什么质的提升。</p>
</li>
<li>
<p>微服务架构的关键不在于具体的实现，而在于如何合理地划分服务边界以及组织架构是否相匹配。不考虑研发团队的规模和组成就盲目上微服务是不良的技术选型。</p>
</li>
<li>
<p>Spring Boot 是 Spring 全家桶的上层封装，并不是什么崭新的技术，也不是什么值得成为自己杀手锏的技术。</p>
</li>
<li>
<p>Spring Cloud 中 Spring Cloud Netflix 的组件是经过生产环境验证的，其他的则建议慎重选择。</p>
</li>
</ul>
<p><strong>微服务是什么</strong></p>
<p>微服务起源于 2005 年 Peter Rodgers 博士在云端运算博览会提出的微 Web 服务(Micro-Web-Service)，根本思想类似于 Unix 的管道设计理念。</p>
<p>2014 年，由 Martin Fowler 与 James Lewis 共同提出了微服务的概念，定义了微服务架构风格是一种通过一套小型服务来开发单个应用的方法，每个服务运行在自己的进程中，并通过轻量级的机制进行通讯（HTTP API）。</p>
<p><strong>关键的三点是：</strong></p>
<ul>
<li><strong>small</strong></li>
<li><strong>automated</strong></li>
<li><strong>lightweight</strong></li>
</ul>
<p>对比 SOA，微服务可以看做是 SOA 的子集，是轻量级的 SOA，粒度更细的服务，独立进程、数据分离，更注重敏捷、持续交付、DevOps 以及去中心化实践。</p>
<p><strong>其共同的架构原理：</strong></p>
<ul>
<li><strong>单一职责</strong></li>
<li><strong>关注分离：控制与逻辑相分离</strong></li>
<li><strong>模块化和分而治之</strong></li>
</ul>
<p><strong>特点：</strong></p>
<ul>
<li><strong>用服务进行组件化</strong></li>
<li><strong>围绕业务能力进行组织</strong></li>
<li><strong>是产品而非项目</strong></li>
<li><strong>端点智能化和哑管道: 控制逻辑都在端点，管道仅仅是传输</strong></li>
<li><strong>全自动化部署</strong></li>
<li><strong>语言和数据的去中心化控制</strong></li>
<li><strong>面向失败设计</strong></li>
<li><strong>渐进式设计</strong></li>
</ul>
<p><strong>综合来看，其优缺点如下：</strong></p>
<ul>
<li><strong>优点：</strong> 模块的强边界；独立部署；技术选型的多样性。</li>
<li><strong>缺点：</strong> 分布式带来编程复杂度，远程调用的消耗；舍弃强一致性，实现最终一致性；操作复杂性要求有一个成熟的运维团队或者运维基础设施。</li>
</ul>
<p><strong>为什么要采用微服务</strong></p>
<p>是否选择微服务取决于你要设计的系统的复杂度。微服务是用来把控复杂系统的，但是随之而来的就是引入了微服务本身的复杂度。</p>
<p>需要解决包括自动化部署、监控、容错处理、最终一致性等其他分布式系统面临的问题。即使已经有一些普遍使用的解决方案，但是仍然是有不小的成本的。</p>
<figure data-type="image" tabindex="1"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/bZVnx0" alt="img" loading="lazy"></figure>
<p>生产力和复杂度的关系如图所示，可见系统越复杂，微服务带来的收益越大。此外，无论是单体应用还是微服务，团队的技能都需要能够把控住。</p>
<p><strong>马丁·福勒的一个观点是：</strong> 除非管理单体应用的成本已经太复杂了（太大导致很难修改和部署），否则都不要考虑微服务。</p>
<p>大部分应用都应该选择单体架构，做好单体应用的模块化而不是拆分成服务。</p>
<p>因此，系统一开始采用单体架构，做好模块化，之后随着系统变得越来越复杂、模块/服务间的边界越来越清晰，再重构为微服务架构是一个合理的架构演化路径。</p>
<p><strong>四个可以考虑上微服务的情况：</strong></p>
<ul>
<li>多人开发一个模块/项目，提交代码频繁出现大量冲突。</li>
<li>模块间严重耦合，互相依赖，每次变动需要牵扯多个团队，单次上线需求太多，风险大。</li>
<li>主要业务和次要业务耦合，横向扩展流程复杂。</li>
<li>熔断降级全靠 if-else。</li>
</ul>
<p><strong>微服务的三个阶段：</strong></p>
<ul>
<li><strong>微服务 1.0：</strong> 仅使用注册发现，基于 Spring Cloud 或者 Dubbo 进行开发。</li>
<li><strong>微服务 2.0：</strong> 使用了熔断、限流、降级等服务治理策略，并配备完整服务工具和平台。</li>
<li><strong>微服务 3.0：</strong> Service Mesh 将服务治理作为通用组件，下沉到平台层实现，应用层仅仅关注业务逻辑，平台层可以根据业务监控自动调度和参数调整，实现 AIOps 和智能调度。</li>
</ul>
<p><strong>微服务架构</strong></p>
<p><strong>先决条件</strong></p>
<p><strong>微服务的先决条件如下：</strong></p>
<ul>
<li><strong>快速的环境提供能力：</strong> 依赖于云计算、容器技术，快速交付环境。</li>
<li><strong>基本的监控能力：</strong> 包括基础的技术监控和业务监控。</li>
<li><strong>快速的应用部署能力：</strong> 需要部署管道提供快速的部署能力。</li>
<li><strong>Devops 文化：</strong> 需要具有良好的持续交付能力，包括全链路追踪、快速环境提供和部署等，还需要快速的反应能力（对问题、故障的快速响应），开发和运维的协同工作。</li>
</ul>
<p>此外，根据康威定律和逆康威定律（技术架构倒逼组织架构改进），组织架构也是一个很关键的因素。</p>
<p><strong>对应于微服务架构，组织架构需要遵循以下原则：</strong></p>
<ul>
<li>一个微服务由一个团队维护，团队成员以三人为宜。</li>
<li>单个团队的任务和发展是独立的，不受其他因素影响。</li>
<li>团队是功能齐全、全栈、自治的，扁平、自我管理。</li>
</ul>
<p><strong>基础设施</strong></p>
<p>微服务的推行需要依赖于很多底层基础设施，包括提供微服务的编译、集成、打包、部署、配置等工作，采用 PaaS 平台解决微服务从开发到运行的全生命周期管理，同时提供异构环境管理、容器资源隔离与互通、服务伸缩漂移、服务升级与回退、服务熔断与降级、服务注册与发现。</p>
<p><strong>①最基本的基础设施</strong></p>
<p><strong>进程间通讯机制：</strong> 微服务是独立进程的，需要确定之间的通讯方式。</p>
<p><strong>服务发现+服务路由：</strong> 提供服务注册中心，服务提供者和消费者通过服务发现获取服务的信息从而调用服务，实现服务的负载均衡等。</p>
<p><strong>服务容错：</strong> 微服务架构中，由于服务非常多，往往是一个服务挂了，整个请求链路的服务都受到影响。</p>
<p>因此需要服务容错，在服务调用失败的时候能够处理错误或者快速失败，包括熔断、Fallback、重试、流控和服务隔离等。</p>
<p><strong>分布式事务支持：</strong> 随着业务拆分为服务，那么有时候不开避免的就是跨服务的事务，即分布式事务的问题。</p>
<p>原则是尽量避免分布式事务，如果无法避免那么可以使用消息系统或者 CQRS 和 Event Sourcing 方案来实现最终一致性。</p>
<p>如果需要强一致性，则有两阶段提交、三阶段提交、TCC 等分布式事务解决方案。</p>
<p><strong>②提升外部服务对接效率和内部开发效率</strong></p>
<p><strong>API 网关：</strong> 负责外部系统的访问，跨横切面的公共层面的工作，包括安全、日志、权限控制、传输加密、请求转发、流量控制等。</p>
<p>典型的网关功能即对外暴露一个域名 xx.com，根据第一级目录做反向路由 xx.com/user，xx.com/trade。</p>
<p>每一级目录，如 user、trade 对应一个服务的域名。此外，API 网关也可以有服务编排的功能（不推荐）。</p>
<p><strong>接口框架：</strong> 规范服务之间通讯使用的数据格式、解析包、自解释文档，便于服务使用方快速上手等。</p>
<p><strong>③提升测试和运维效率</strong></p>
<p><strong>配置中心:</strong>  运行时配置管理能够解决动态修改配置并批量生效的问题。包括配置版本管理、配置项管理、节点管理、配置同步等。</p>
<p><strong>持续交付：</strong> 包括持续集成、自动化部署等流程。目的就是小步迭代，快速交付。</p>
<p><strong>持续集成：</strong> 这一部分并非是微服务特定的，对于之前的单体应用，此部分一般来说也是必要的。</p>
<p>主要是指通过自动化手段，持续地对代码进程编译构建、自动化测试，以得到快速有效的质量反馈，从而保证代码的顺利交付。</p>
<p>自动化测试包括代码级别的单元测试、单个系统的集成测试、系统间的接口测试。</p>
<p><strong>自动化部署：</strong> 微服务架构，节点数动辄上百上千，自动化部署能够提高部署速度和部署频率，从而保证持续交付。</p>
<p>包括版本管理、资源管理、部署操作、回滚操作等功能。而对于微服务的部署方式，包括蓝绿部署、滚动部署以及金丝雀部署。</p>
<p><strong>④进一步提升运维效率</strong></p>
<p><strong>服务监控：</strong> 微服务架构下节点数目众多，需要监控的机器、网络、进程、接口等的数量大大增加，需要一个强大的监控系统，能够提供实时搜集信息进行分析以及实时分析之上的预警。</p>
<p>包括监控服务的请求次数、响应时间分布、最大/最小响应值、错误码分布等。</p>
<p><strong>服务跟踪：</strong> 跟踪一个请求的完整路径，包括请求发起时间、响应时间、响应码、请求参数、返回结果等信息，也叫做全链路跟踪。</p>
<p>通常的服务可以和服务监控做在一起，宏观信息由服务跟踪呈现，微观单个服务/节点的信息由服务监控呈现。服务跟踪目前的实现理论基本都是 Google 的 Dapper 论文。</p>
<p><strong>服务安全：</strong> 内网之间的微服务调用原则上讲应该是都可以互相访问写，一般并不需要权限控制，但有时候限于业务要求，会对接口、数据等方面有安全控制的要求。</p>
<p>此部分可以以配置的方式存在于服务注册中心中，和服务绑定，在请求时由做为服务提供者的服务节点进行安全策略控制。配置则可以存储在配置中心以方便动态修改。</p>
<p>在微服务数量很少的情况下，以上基础设施的优先级自上而下降低。否则，仅仅依赖人工操作，则投入产出比会很低。</p>
<p>还需要提到的是 Docker 容器技术。虽然这个对于微服务并不是必须的，但是容器技术轻量级、灵活、与应用依存、屏蔽环境差异的特性对于持续交付的实现是至关重要的，即使对于传统的单体应用也能够给其带来交付效率的大幅提升。</p>
<p><strong>架构设计模式</strong></p>
<p>在引入微服务之后，传统的单体应用变为了一个一个服务，之前一个应用直接提供接口给客户端访问的架构不再适用。</p>
<p>微服务架构下，针对不同设备的接口做为 BFF 层（Backend For Frontend），也叫做用户体验适配层，负责聚合、编排微服务的数据转换成前端需要的数据。</p>
<p>服务之间的调用则在允许的情况下（允许延迟）尽可能使用异步消息传递方式，如此形成面向用户体验的微服务架构设计模式。</p>
<p><strong>如下图所示：</strong></p>
<figure data-type="image" tabindex="2"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/crkgUc" alt="img" loading="lazy"></figure>
<p>Client→API Gateway→BFF（Backend For Frontend）→Downstream Microservices：</p>
<ul>
<li>后台采用微服务架构，微服务可以采用不同的编程语言和不同的存储机制。</li>
<li>前台采用 BFF 模式对不同的用户体验（如桌面浏览器，Native App，平板响应式 Web）进行适配。</li>
<li>BFF、API Orchestration Layer，Edge Service Layer，Device Wrapper Layer 是相同的概念。</li>
<li>BFF 不能过多，过多会造成代码逻辑重复冗余。</li>
<li>可以将网关承担的功能，如 Geoip、限流、安全认证等跨横切面功能和 BFF 做在同一层，虽然增加了 BFF 层的复杂性，但能够得到性能优势。</li>
</ul>
<p><strong>服务拆分</strong></p>
<p>微服务架构最核心的环节，主要是对服务的横向拆分。服务拆分就是将一个完整的业务系统解耦为服务，服务需要职责单一，之间没有耦合关系，能够独立开发和维护。</p>
<p>服务拆分不是一蹴而就的，需要在开发过程中不断地理清边界。在完全理清服务之前，尽量推迟对服务的拆分，尤其是对数据库的拆分。</p>
<p><strong>拆分方法如下：</strong></p>
<ul>
<li><strong>基于业务逻辑拆分</strong></li>
<li><strong>基于可扩展拆分</strong></li>
<li><strong>基于可靠性拆分</strong></li>
<li><strong>基于性能拆分</strong></li>
</ul>
<p>其中，对于无法修改的遗留系统，采用绞杀者模式：在遗留系统外面增加新的功能做成微服务方式，而不是直接修改原有系统，逐步的实现对老系统替换。</p>
<p><strong>拆分过程需要遵守的规范如下：</strong></p>
<ul>
<li>先少后多、先粗后细（粒度）</li>
<li>服务纵向拆分最多三层，两次调用：Controller、组合服务、基础服务</li>
<li>仅仅单向调用，禁止循环调用</li>
<li>串行调用改为并行调用或者异步化</li>
<li>接口应该幂等</li>
<li>接口数据定义严禁内嵌，透传</li>
<li>规范化工程名</li>
<li>先拆分服务，等服务粒度确定后再拆分数据库。</li>
</ul>
<p><strong>微服务框架</strong></p>
<p>上面讲述了微服务架构的众多基础设施，如果每一个基础设施都需要自己开发的话是非常巨大的开发工作。目前市面上已经有不少开源的微服务框架可以选择。</p>
<p><strong>Spring Boot</strong></p>
<p>Spring Boot 是用来简化新 Spring 应用的初始搭建以及开发过程的。其虽然不是微服务框架，但其设计的初衷本质就是微应用的底层框架，因此非常适合用于微服务基础设施的开发以及微服务的应用开发。</p>
<p>尤其对于 Spring 技术栈的团队来说，基于 Spring Boot 开发微服务框架和应用是自然而然的一个选择。关注微信公众号：Java技术栈，在后台回复：boot，可以获取我整理的 N 篇最新 Spring Boot 教程，都是干货。</p>
<p><strong>Dubbo&amp;Motan</strong></p>
<p>Dubbo 是阿里开源的服务治理框架。其出现在微服务理念兴起之前，可以看做是 SOA 框架的集大成之作。</p>
<p><strong>但其仅仅包含了微服务基础设施的部分功能，诸如熔断、服务跟踪、网关等都没有实现：</strong></p>
<ul>
<li><strong>服务发现：</strong> 服务发布、订阅、通知。</li>
<li><strong>高可用策略：</strong> 失败重试（Failover）、快速失败（Failfast）、资源隔离 - 负载均衡 ：最少活跃连接、一致性 Hash、随机请求、轮询等。</li>
<li><strong>扩展性 ：</strong> 支持 SPI 扩展（service provider interface）。</li>
<li><strong>其他 ：</strong> 调用统计、访问日志等。</li>
</ul>
<p>Motan 则是微博开源的类似 Dubbo 的 RPC 框架，与 Dubbo 相比更轻量级。</p>
<p><strong>Spring Cloud</strong></p>
<p>Spring Cloud 是基于 Spring Boot 实现的微服务框架，也可以看做一套微服务实现规范。关注微信公众号：Java技术栈，在后台回复：cloud，可以获取我整理的 N 篇最新 Spring Cloud 教程，都是干货。</p>
<p>基本涵盖了微服务基础设施的方方面面，包括配置管理、服务发现、断路器、智能路由、微代理、控制总线、全局锁、决策竞选、分布式会话和集群状态管理等。</p>
<p>其基于 Spring 生态，社区支持非常好。但其很多组件都没有经过生产环境验证，需要慎重选择。</p>
<p>Spring Cloud Netflix 是 Spring Cloud 的一个子项目，是 Spring 对 Netflix OSS 的集成实现。</p>
<p><strong>基于 Netflix 的大规模使用，其中的已经被广泛使用的组件包括：</strong></p>
<ul>
<li><strong>Eureka：</strong> 服务注册和服务发现</li>
<li><strong>Ribbon：</strong> 弹性而智能的进程间和服务通讯机制，客户端负载均衡</li>
<li><strong>Hystrix：</strong> 熔断器，在运行时提供延迟和容错的隔离</li>
<li><strong>Zuul：</strong> 服务网关</li>
</ul>
<p>此外，另一个子项目 Spring Cloud Alibaba 则是 Alibaba 开源的基于 Spring Boot 的微服务框架，主要是对阿里云服务的支持。</p>
<p><strong>Service Mesh</strong></p>
<p>上述的微服务框架都是侵入式的，服务化的过程都需要进行代码改造。Service Mesh 则是下一代微服务架构，最明显的特征就是无入侵。采用 Sidecar 模式来解决系统架构微服务化后的服务间通信和治理问题。</p>
<p><strong>如下图所示：</strong></p>
<p><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/1hjB5S" alt="img" loading="lazy"><br>
<strong>目前主流的开源实现包括：</strong></p>
<ul>
<li>
<p><strong>Linkerd 和 Envoy：</strong> 以 Sidecar 为核心，关注如何做好 Proxy，并完成一些通用控制平面的功能。缺乏对这些 Sidecar 的管理和控制。</p>
</li>
<li>
<p><strong>Istio 和 Conduit：</strong> 目前最为流行的 Service Mesh 实现方案，集中在更加强大的控制平面(Sidecar 被称为数据平面)功能。</p>
<p>前者由 Google 和 IBM 合作，并使用了 Envoy 作为 Sidecar 部分的实现；后者则是 Linkerd 作者的作品。</p>
<p>相比起来，Istio 有巨头背景，功能强大，但可用性和易用性一直不高，Conduit 则相对简单、功能聚焦。</p>
</li>
</ul>
<p>限于 Service Mesh 带来的性能延迟的开销以及 Sidecar 对分布复杂性的增加，其对大规模部署(微服务数目多)、异构复杂(交互协议/开发语言类型多)的微服务架构带来的收益会更大。</p>
<p><strong>Sofastack</strong></p>
<p>蚂蚁金服开源的构建金融级分布式架构的一套中间件。包括微服务开发框架、RPC 框架、服务注册中心、全链路追踪、服务监控、Service Mesh 等一整套分布式应用开发工具。</p>
<p>特别值得一提的是 SOFAMesh。其实对下一代微服务架构 Service Mesh 的大规模落地方案实践，基于 Istio 改进和扩展而来，应该是国内最为成熟的开源 Service Mesh 方案。</p>
<p>此外，需要提到 Kubernetes（K8s），其本身提供了部分的微服务特性支持（通过域名做服务发现），对代码无侵入。但服务调用、熔断这些都需要自己实现。</p>
<figure data-type="image" tabindex="3"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/le2NKP" alt="img" loading="lazy"></figure>
<p>综上，目前公司技术团队技术栈是 Spring，并且已有服务的实现都是基于 Dubbo。</p>
<p>因此选择 Spring Cloud Netflix 做为基础的微服务框架，对其中不成熟或者缺乏的组件，选择业界更为成熟的组件替代即可：</p>
<ul>
<li><strong>API 网关：</strong> Zuul。</li>
<li><strong>服务注册中心：</strong> Dubbo。</li>
<li><strong>配置中心：</strong> Disconf。</li>
<li><strong>服务监控&amp;全链路追踪：</strong> CAT。</li>
<li><strong>服务开发框架：</strong> Spring Boot。</li>
<li><strong>日志监控、告警：</strong> ELK+Elasalert。</li>
<li><strong>流量控制：</strong> Sentinel。</li>
<li><strong>消息队列：</strong> Kafka。</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[微服务设计 10 大反模式和陷阱]]></title>
        <id>https://kangjn.github.io/post/wei-fu-wu-she-ji-10-da-fan-mo-shi-he-xian-jing/</id>
        <link href="https://kangjn.github.io/post/wei-fu-wu-she-ji-10-da-fan-mo-shi-he-xian-jing/">
        </link>
        <updated>2021-04-22T07:49:39.000Z</updated>
        <content type="html"><![CDATA[<p>O’Reilly的电子书《Microservices AntiPatterns and Pitfalls》讲述了在微服务设计实现时十种最常见的反模式和陷阱。本文基于此书，将这十个点列出。</p>
<p>数据驱动迁移反模式（Data-Driven Migration）</p>
<figure data-type="image" tabindex="1"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/678393.png" alt="img" loading="lazy"></figure>
<p>如上图所示，此种反模式的问题在于微服务的粒度没有最终确定之前就做了数据迁移，如此当不断的调整服务粒度时，那么数据库就免不了频繁迁移，带来极大的成本。更好的方式如下图所示：</p>
<figure data-type="image" tabindex="2"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/758392.png" alt="img" loading="lazy"></figure>
<p>即先分离功能，数据库先保持之前的单体，等到服务粒度最终确定之后，再分离数据库。</p>
<p>超时反模式（The Timeout）</p>
<p>微服务架构是由一系列分离的服务组成的，这些服务之间通过一些远程协议进行互相之间的通信。其中牵扯到了服务的可用性和响应性问题。如下图所示：</p>
<figure data-type="image" tabindex="3"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/921392.png" alt="img" loading="lazy"></figure>
<ul>
<li>可用性：服务消费方能够连接服务方，并可以向其发送请求。</li>
<li>响应性：服务方能够在消费方期望时间内给予请求响应。</li>
</ul>
<p>为了防止服务的不可用和无法响应，通常的做法就是设置一个调用超时。此种做法表面上看是没问题的，但是试想一下如下情景：发起一个购买100个商品的请求，请求成功返回一个确认号。如果当请求超时但是请求在服务端已经成功执行了，此时这个交易实际是完成的，但是消费方没有拿到确认号，如果重试请求，那么服务方需要一个复杂的机制判断这是否一次重复提交。</p>
<p>一种解决此问题的方案是设置一个较长的超时时间，如一个服务的通常响应耗时需要2s，最大耗时需要5s，那么超时时间可以设置为10s。但这样的问题就是如果服务不可用，所有消费方都得等待10s，这个是非常损耗性能的。</p>
<p>解决超时反模式的方案就是使用“断路器模式”。就类似于房屋中的电源断路器，当断路器关闭，电流可以通过，当断路器打开，那么电流中断一直到断路器关闭。断路器模式就是说当检测到服务方无法响应时就打开，后续的请求都会被拒绝掉。一旦服务方可响应了，那么断路器关闭，恢复请求。其工作模式如下图所示：</p>
<figure data-type="image" tabindex="4"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/020392.png" alt="img" loading="lazy"></figure>
<p>断路器会持续地监测远程服务，确保其是可响应的。只要服务可响应，那么断路器会一直关闭，允许请求通过。如果服务突然不可响应，那么断路器打开，拒绝后续的请求。而后续如果断路器又检测到服务恢复了，那么断路器会自动关闭，请求也就恢复了。此种方案与超时时间相比，最大的优势就是一旦服务不可响应，那么断路器模式可以让请求立刻返回而不是需要等待一定的时间。</p>
<p>[Hystrix]的Netflix是此种断路器模式的一种开源实现。此外，Akka中也包含了一个断路器实现：Akka CircuitBreaker类。</p>
<p>共享反模式（“I Was Taught to Share”）</p>
<p>微服务被普遍认为是一种不共享任何东西的架构。但实际上只能是尽可能地少共享，毕竟在某些层面代码被多个服务共享也能带来一定好处。</p>
<p>例如，与单独部署一套安全服务（认证和授权）其他所有服务都通过远程访问此服务相比，把安全相关的功能封装成jar包（security.jar），然后其他服务都集成此jar包，就能够避免每次都要发起对安全服务的访问，从而提高性能和可靠性。但后面的方案带来的问题就是依赖噩梦：每一个服务都依赖多个自定义的jar包。如此不仅打破了服务之间的边界上下文，同时也引入了诸如总体可靠性、变更控制、易测试性、部署等问题。</p>
<p>在一个使用面向对象编程语言的单体应用中，使用abstract类和接口实现代码复用和共享是一个良好的实践。但当从单体切换到微服务架构时，对于很多自定义的共享类和工具类（日期、字符串、计算）的处理要考虑到微服务间共享的东西越少越有利于保持服务间的边界上下文，从而更利于快速测试和部署。以下是几种推荐的方式，也是解决“共享反模式”的方案：</p>
<p><strong>共享项目</strong></p>
<figure data-type="image" tabindex="5"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/257392.jpg" alt="257392" loading="lazy"></figure>
<p>将共享的代码作为一个项目在编译期与各个服务集成。此种方式便于变更和开发软件，但是最大的问题在于很难发觉哪一个共享模块被修改以及修改的原因，也无法确定自己的服务是否需要这些变更。尤其是在服务发布前期发现某一个共享模块发生了变动的话需要再一次的测试才能走后续流程。</p>
<p><strong>共享库</strong></p>
<figure data-type="image" tabindex="6"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/358392.jpg" alt="358392" loading="lazy"></figure>
<p>此种方式即将共享的代码作为类库集成到服务中。如此每次共享的库有改动，服务都需要重新打包、测试、重启。但相比起第一种，其有版本标记，能够更好地控制服务的部署和开发，服务开发者可以自己控制何时将共享库的改动集成进来。</p>
<p>更进一步的，如果采用此种方案，一定要避免把所有共享的代码都打包进一个jar包中如common.jar。否则会很难确定何时要把库的变动集成到服务中。更好的做法是将共享代码分成几个单独上下文的库，如：security.jar、dateutils.jar、persistence.jar等，如此会比较容易的确定何时去集成共享库的变动。</p>
<p><strong>冗余</strong></p>
<figure data-type="image" tabindex="7"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/454393.png" alt="img" loading="lazy"></figure>
<p>此种方案违反DRY原则，在每一服务中都冗余一份共享代码，能够避免依赖共享也能够保持边界上下文。但是一旦共享的代码有变动，那么所有服务都需要改动。因此，此种方案适用于共享模块非常稳定，极小可能变动的情况。</p>
<p><strong>服务合并</strong></p>
<figure data-type="image" tabindex="8"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/563392.png" alt="img" loading="lazy"></figure>
<p>当多个服务共享的代码变动比较频繁时可以采用此种方案合并成一个服务，如此就避免了多了服务频繁的测试和部署，也避免了依赖共享库。</p>
<p>可达性报告反模式（Reach-in Reporting）</p>
<p>微服务中各个服务以及其相应的数据都是包含在一个单独的边界上下文中的，也就是说数据是隔离到多个数据库中的。因此，这也会使得收集微服务的各种数据生成报告变得相对困难。一般来说有四种方案解决这个问题。其中，前三种都是从各个微服务中拉取数据，是这里所说的反模式，被称作“Reach-in Reporting”。</p>
<p><strong>数据库拉取模式</strong></p>
<figure data-type="image" tabindex="9"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/732392.png" alt="img" loading="lazy"></figure>
<p>报告服务直接从各个服务的数据库中拉取数据从而生成各种报告。此种方式简单迅速，但是会让报告服务和业务服务相互依赖，是一种数据库共享集成风格（通过共享的数据库将多个应用耦合在一起）。如此一旦数据库有改动，所有相关服务都要改动，也就打破了微服务中极为重要的边界上下文。</p>
<p><strong>HTTP拉取模式</strong></p>
<figure data-type="image" tabindex="10"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/820392.png" alt="img" loading="lazy"></figure>
<p>与数据库拉取模式相比，此种方式不再是直接去访问服务的数据库，而是通过HTTP接口去请求服务的数据。此种方式能够保持服务的边界上下文，但是性能比较慢，而且HTTP请求无法很好的承载大数据。</p>
<p><strong>批量拉取模式</strong></p>
<figure data-type="image" tabindex="11"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/931392.png" alt="img" loading="lazy"></figure>
<p>此种方式会有一个单独的报告数据库/数据仓库来存储各个服务的聚合数据。会通过一个批量任务（离线或者基于增量实时）将服务更新的数据导入到报告数据库/数据仓库中。与数据库拉取模式一样，此种方式这也是一种数据库共享集成风格，会打破服务的边界上下文。</p>
<p><strong>异步事件推送模式</strong></p>
<figure data-type="image" tabindex="12"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/068392.png" alt="img" loading="lazy"></figure>
<p>此种方式即解决“Reach-in  Reporting”反模式的方案。每个服务都把自己的发生的事件异步推送到一个数据捕获服务，后续数据捕获服务会将数据解析存储到报告数据库中。此种方式实现起来较复杂，需要在服务和数据捕获服务之间制定一种协议用于异步传输事件数据。但其能够保持服务的边界上下文，同时也能保证数据的时效性。</p>
<p>沙粒陷阱（Grains of Sand）</p>
<p>微服务实现中最有挑战的问题在于如何拆分service，如何控制服务的粒度，而正确的服务粒度则决定了微服务是否能够成功实现。服务粒度也能够影响到性能、健壮性、可靠性、易测试性、部署等。</p>
<p>“沙粒陷阱”即把服务拆分的太细。其中的一个原因就是很多时候开发者会把一个class与一个服务等同。合理的，应该是一个服务组件（Service component）对应一个服务。一个服务组件具有清晰、简洁的角色、职责，具有一组定义好的操作。其一般通过多个模块（Java  Class）实现。如果组件和模块是一对一的关系，那么不仅仅会造成服务粒度过细同时也是一种不好的编程实践：服务的实现都是通过一个Class，那么此Class会非常大并且承担太多的责任，不利于测试和维护。</p>
<p>更进一步的，服务的粒度并不应该受其中实现类的数目影响：有些服务可能只需要一个类就可以实现，而有些服务会需要多个类来实现。</p>
<p>为了避免“沙粒陷阱”，可以通过以下三种测试来判断服务粒度是否合理：</p>
<p><strong>分析服务范围和功能</strong></p>
<p>要明确服务用来干什么？有哪些操作？一般通过使用文档或者语言来描述服务的范围和功能就能够看出来服务是否做的工作太多。如果在描述中使用了“和”（“and”）或者“此外”（“in addition”）之类的词，很有可能就是此服务职责太多。</p>
<p>服务的高内聚是一种良好的实践，其明确一个服务提供的操作之间必须要是有关联的。如对于一个顾客服务，有以下操作：</p>
<ul>
<li>添加顾客</li>
<li>更新顾客信息</li>
<li>获取顾客信息</li>
<li>通知顾客</li>
<li>记录顾客评论</li>
<li>获取顾客评论</li>
</ul>
<p>其中的前三个操作都是对顾客的CRUD操作，是相关联的。而后三者则无关。为了实现服务的高内聚，合理的应该是把此服务拆分成三个服务：顾客维护、顾客通知、顾客评论。</p>
<p>如此，以粗粒度的服务开始，然后逐渐拆分成细粒度的服务有利于对微服务的拆分。</p>
<p><strong>分析数据库事务</strong></p>
<p>传统的关系型数据库都提供了ACID事务特性用于把多个更新操作打包成一个整体提交，要么都成功，要么都失败。而在微服务中，由于服务都是一个个分离的应用，很难实现ACID，一般实现BASE事务（basic availability、soft state、eventual  consistence）即可。但是无法避免的，仍然会有一些场景是需要ACID的。因此，当你不断的需要在BASE和ACID事务做判断和取舍的时候，很有可能就是服务粒度过细。</p>
<p>如果业务场景无法接受最终一致性，那么最好就是将服务粒度粗化一些，把多个更新操作放到一个服务中。</p>
<p><strong>分析服务编排</strong></p>
<p>这里主要说的是服务之间的互相通信。由于对服务的调用都是一次远程调用，因此服务编排会非常大的影响微应用总体的性能。此外，它也会影响系统整体的健壮性和可靠性，越多的远程调用，那么越高的几率会有失败或者超时的请求出现。</p>
<p>如果发现完成一次业务逻辑需要调用太多的远程服务，就说明服务的粒度可能太细了。这时候就需要将服务粗化。而合并细粒度服务还能够提高性能，提升总体的健壮性和可靠性。同时也减少了多个服务间的依赖，更利于测试和部署。</p>
<p>此外，使用响应式编程技术异步并行调用远程服务也是一种提升性能和可靠性的方案。</p>
<p>无因的开发者陷阱（Developer Without a Cause）</p>
<p>此陷阱主要讲的是开发者或者架构师在做设计时很多时候是拍脑袋在做，没有任何合理的原因或者原因是错误的，也不会做取舍。而想要解决此问题，不仅仅是架构师，开发者也需要同时了解技术带来的好处以及缺陷，从中做权衡。</p>
<p>了解业务驱动是避免此陷阱的关键一步。每一个开发者和架构师都应该清楚的了解下面这些问题的答案：</p>
<ul>
<li>为什么要使用微服务？</li>
<li>最重要的业务驱动是什么？</li>
<li>架构中的哪一点是最为重要的？</li>
</ul>
<p>假如易部署性、性能、健壮性、可扩展性是系统最看重的特性，那么对于不同的业务侧重点，微服务的粒度需求也是不同的。细粒度的服务能够达到更好的易测试性和易部署性，而粗粒度的服务则有更好的性能、健壮性以及可靠性。</p>
<p>追随流行陷阱（Jump on the Bandwagon）</p>
<p>微服务是目前非常流行的架构理念，越来越多的公司也都在紧跟这个潮流纷纷转型微服务架构，而不管到底自己是否真的需要。为了避免此陷阱，需要首先了解微服务的优点和缺点。</p>
<p>优点：</p>
<ul>
<li>易部署：容易部署是微服务的一个很大的优点。毕竟相比起一个庞大的单体应用，一个小并且职责单一的微服务的部署非常简单并且带来的风险也会小很多。而持续部署技术则进一步放大了这个优点。</li>
<li>易测试：职责单一、共享依赖少使得测试一个微服务是很容易的。而基于微服务做回归测试与单体大应用相比也是很容易的。 控制变更：每个服务的范围和边界上下文使得很容易控制服务的功能变动。</li>
<li>模块化：微服务就是一个高度模块化的架构风格。这种风格也是一种敏捷方式的表达，能够很快的响应变化。一个系统模块化程度越高，就越容易测试、部署和发布变更。一个服务粒度划分合理的微服务系统是所有架构中模块化程度最高的架构形式。</li>
<li>可扩展性：由于每一个服务都是一个职责单一的细粒度服务，因此此种架构风格是所有架构分隔中可扩展性最高的。其非常容易扩展某一个或者某几个功能从而满足整体系统的需求。而得益于服务的容器化特性以及各种运维监控工具，服务也能够自动化进行启动和关闭。</li>
</ul>
<p>缺点：</p>
<ul>
<li>组织变动：微服务需要组织在很多层面进行变动。研发团队需要包含UI、后端开发、规则处理、数据库处理建模等多种职位，从而使得一个小的团队能够具有实现微服务的所有技术栈。同时，传统的单体、分层应用架构的软件发布流程也需要更新为自动化、高效的部署流水线。</li>
<li>性能：由于服务都是隔离的，因此发起对服务的远程调用肯定是会影响性能的。服务编排、运行环境都是影响性能的很大因素。了解远程调用的延迟、需要与多少服务通信都是与性能相关的需要掌握的信息。</li>
<li>可靠性：和性能一样。服务的远程调用越多，那么失败的几率就越高，总体的可靠性就会越低。</li>
<li>DevOps：随着微服务架构而来的是成千上百的服务。手动管理这么多的服务是很不现实的。这就对于自动化运维部署、协作提出了很高的挑战。需要依赖非常多的操作工具和实践，是一个非常复杂的工作。目前差不多有12种类型的操作工具（监控工具、服务注册、发现工具、部署工具等）和框架在微服务架构中被使用，其中每一种又包含了很多具体的工具和产品供选择。对于这些工具和框架的选择一般都会需要将近数月的研究、测试、权衡分析才能做出最适合的技术选型。</li>
</ul>
<p>了解了微服务的优缺点后，下一步则需要根据实际的业务来分析微服务是不是解决这些问题的最佳方案。可以采取以下问题：</p>
<ul>
<li>业务和技术的目标是什么？</li>
<li>使用微服务是为了完成什么？</li>
<li>目前和可预知的痛点是什么？</li>
<li>应用的最关键的技术特性是什么？（性能、易部署性、易测试性、可扩展性）</li>
</ul>
<p>回答这些问题再结合微服务的优缺点能够让你明确现在是否是使用微服务的适当时机。</p>
<p>除了微服务以外，还有其他7种比较普遍使用的架构供选择：</p>
<ul>
<li>基于服务的架构（Service-Based）</li>
<li>面向服务的架构（Service-Oriented）</li>
<li>分层架构（Layered）</li>
<li>微内核架构（Microkernel）</li>
<li>基于空间的架构（Space-Based）</li>
<li>事件驱动架构（Event-Driven）</li>
<li>流水线架构（Pipeline）</li>
</ul>
<p>静态合约陷阱（The Static Contract）</p>
<p>微服务的消费方和服务提供方之间会有一个合约/协议用来规定输入输出数据的格式、操作名称等等。一般情况下这个合约是不变的。但是如果没有使用版本号来管理服务接口，那么就会进入“静态合约”陷阱。</p>
<p>给合约打上版本标记不仅仅能够避免巨大的变动（服务提供方修改合约使得所有消费方也都得修改），还能够提供向后兼容性。这里有两种技术可以实现合约的版本号：</p>
<p><strong>在头部信息附加版本号</strong></p>
<figure data-type="image" tabindex="13"><img src="http://img.javastack.cn/1588152255455392.png" alt="img" loading="lazy"></figure>
<p>此种方式即在远程访问协议的头部添加版本信息。而如果远程协议使用的是REST，那么还可以使用vendor mime type（vnd）来指定合约的版本号。如下：</p>
<pre><code>POST /trade/buy
Accept: application/vnd.svc.trade.v2+json
</code></pre>
<p>服务接受到请求，能够通过正则等手段简单解析出其中的合约版本号再根据版本号做相应的处理。</p>
<p>如果使用消息队列，那么可以将版本号放置在属性部分(Property section)。JMS的一个例子如下：</p>
<pre><code>String msg = createJSON(&quot;acct&quot;,&quot;12345&quot;,&quot;sedol&quot;,&quot;2046251&quot;,&quot;shares&quot;,&quot;1000&quot;);
jsmContext.createProducer()
  .setProperty(&quot;version&quot;,2)
  .send(queue,msg);
</code></pre>
<p><strong>在合约本身中附加版本号</strong></p>
<p>此种方式版本号独立于远程访问协议，与头部信息版本号相比，这也是其最大的优点。但与此同时，其缺点比较多。首先要从请求信息主体中解析版本号，会出现很多解析的问题。其次，合约的模式可能会非常复杂，使得很难做数据转换。最后，服务还要引入对模式的验证逻辑。</p>
<p>我们到了吗陷阱（Are We There Yet）</p>
<p>微服务架构中，各个服务都是独立的个体，也就意味着所有客户端或者API层和服务之间的通信都是一次远程调用。如果对这些远程调用的耗时没有什么概念，那么就陷入了“Are We There  Yet”陷阱。合理的做法需要去测试远程访问的平均延迟、长尾延迟（95%、99%、99.%之外的请求延迟）等指标。而很多时候即使有很好的平均延迟，但是较差的长尾延迟会造成非常大的破坏。</p>
<p>在生产环境或者准生产环境测试有助于去了解应用的真实性能。例如，一个业务请求需要调用四个服务，假设一个服务调用的延迟是100毫秒，那么加上业务请求本身的延迟，完成此次业务请求共需要500毫秒的延迟。这和单单从代码上去看得出的结论是不一样的。</p>
<p>了解目前所用协议的平均延迟是一方面，另一方面则需要对比其他远程协议的延迟，从而在合适的地方使用合适的协议。如：JMS、AMQP、MSMQ。</p>
<p>AMQP协议的性能是最好的。那么结合业务场景，就可以选择REST作为客户端与服务间的通信协议，AMQP做为服务之间的通信协议以提高应用的性能。</p>
<p>当然，性能并非在选择远程协议时唯一考虑的因素。下一节中就会考虑利用消息队列的一些额外功能。</p>
<p>REST使用陷阱（Give It a Rest）</p>
<p>REST现在是微服务中用的最多的通信协议。流行的开发框架如DropWizard、Spring  Boot都提供了REST支持。但是如果只选择REST这一种协议，不去考虑其他诸如消息队列的优势，那么就陷入了“REST使用”陷阱。毕竟异步通信、广播、合并请求事务这些需求，REST是很难实现的。</p>
<p>消息队列标准目前包括平台特定和平台无关两种。前者包括Java平台中的JMS和C#平台的MSMQ，后者则是AMQP。对于平台特定的消息标准JMS，其规范了API，因此切换broker实现（ActiveMQ、HornetQ）时无需修改API，但由于底层通信协议是不同的，集成的客户端或者服务端jar包需要随着修改。</p>
<p>对于平台无关的消息标准，其规范了协议实现标准，并没有规范API。使得不同平台之间都可以互相通信，而不管实际产品是什么。如一个使用了RabbitMQ的客户端可以很容易地与一个StormMQ通信（假设使用的协议相同）。也就是其独立于平台的特性使得RabbitMQ成为微服务架构中最流行的消息队列。</p>
<p><strong>异步请求</strong></p>
<p>异步通信是消息队列适用的场景之一。服务消费者发起请求后无需等待服务方响应能够提高总体的性能，同时调用方无需担心调用超时，也就无需使用断路器，从而提高了系统的可靠性。</p>
<p><strong>广播</strong></p>
<p>将消息广播给多个service是消息队列的又一个适用场景。一个消息生产者向多个消息接受者发送消息，无需知道谁在接受消息以及如何处理它。</p>
<p><strong>事务请求</strong></p>
<p>消息系统提供了对事务消息的支持：如果多个消息被发送到了在一个交易上下文的多个队列或者主题中时，那么直到消息发送者commit，服务才会真正的接受到相应的所有消息（在commit之前会一直保存在队列中）。</p>
<p>因此对于服务消费者需要合并多个远程请求到一个事务中的场景可以选择事务消息。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java 多线程]]></title>
        <id>https://kangjn.github.io/post/java-duo-xian-cheng/</id>
        <link href="https://kangjn.github.io/post/java-duo-xian-cheng/">
        </link>
        <updated>2021-04-22T06:17:23.000Z</updated>
        <content type="html"><![CDATA[<p><strong>线程</strong></p>
<p>线程的概念，百度是这样解释的：</p>
<p>线程（英语：Thread）是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务。</p>
<p>在Unix System V及SunOS中也被称为轻量进程（Lightweight Processes），但轻量进程更多指内核线程（Kernel Thread），而把用户线程（User Thread）称为线程。</p>
<p><strong>1.1 线程与进程的区别</strong></p>
<figure data-type="image" tabindex="1"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/778301.png" alt="" loading="lazy"></figure>
<p>进程：指在系统中正在运行的一个应用程序；程序一旦运行就是进程；进程——资源分配的最小单位。</p>
<p>线程：系统分配处理器时间资源的基本单元，或者说进程之内独立执行的一个单元执行流。线程——程序执行的最小单位。</p>
<p>也就是，进程可以包含多个线程，而线程是程序执行的最小单位。</p>
<p><strong>1.2 线程的状态</strong></p>
<figure data-type="image" tabindex="2"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/129301.png" alt="" loading="lazy"></figure>
<ul>
<li>NEW：线程刚创建</li>
<li>RUNNABLE: 在JVM中正在运行的线程，其中运行状态可以有运行中RUNNING和READY两种状态，由系统调度进行状态改变。</li>
<li>BLOCKED：线程处于阻塞状态，等待监视锁，可以重新进行同步代码块中执行</li>
<li>WAITING : 等待状态</li>
<li>TIMED_WAITING: 调用sleep() join() wait()方法可能导致线程处于等待状态</li>
<li>TERMINATED: 线程执行完毕，已经退出</li>
</ul>
<p><strong>1.3 Notify和Wait ：</strong></p>
<p>Notify和Wait 的作用</p>
<p>首先看源码给出的解释，这里翻译了一下：</p>
<p>Notify：唤醒一个正在等待这个对象的线程监控。如果有任何线程正在等待这个对象，那么它们中的一个被选择被唤醒。选择是任意的，发生在执行的酌情权。一个线程等待一个对象通过调用一个{@code wait}方法进行监视。</p>
<p>Notify()需要在同步方法或同步块中调用，即在调用前，线程也必须获得该对象的对象级别锁</p>
<p>Wait：导致当前线程等待，直到另一个线程调用{@link java.lang.Object#notify()}方法或{@link java.lang.Object#notifyAll()}方法。</p>
<p>换句话说，这个方法的行为就像它简单一样执行调用{@code wait(0)}。当前线程必须拥有该对象的监视器。</p>
<p>线程释放此监视器的所有权，并等待另一个线程通知等待该对象的监视器的线程，唤醒通过调用{@code notify}方法或{@code notifyAll}方法。然后线程等待，直到它可以重新取得监视器的所有权，然后继续执行。</p>
<p>Wait()的作用是使当前执行代码的线程进行等待，它是Object类的方法，该方法用来将当前线程置入预执行队列中，并且在Wait所在的代码行处停止执行，直到接到通知或被中断为止。</p>
<p>在调用Wait方法之前，线程必须获得该对象的对象级别锁，即只能在同步方法或同步块中调用Wait方法。</p>
<p>Wait和Sleep的区别：</p>
<ul>
<li>它们最大本质的区别是，Sleep()不释放同步锁，Wait()释放同步锁。</li>
<li>还有用法的上的不同是：Sleep(milliseconds)可以用时间指定来使他自动醒过来，如果时间不到你只能调用Interreput()来强行打断；Wait()可以用Notify()直接唤起。</li>
<li>这两个方法来自不同的类分别是Thread和Object</li>
<li>最主要是Sleep方法没有释放锁，而Wait方法释放了锁，使得其他线程可以使用同步控制块或者方法。</li>
</ul>
<p><strong>1.4 Thread.sleep() 和Thread.yield()的异同</strong></p>
<ul>
<li>相同 ：Sleep()和yield()都会释放CPU。</li>
<li>不同：Sleep()使当前线程进入停滞状态，所以执行Sleep()的线程在指定的时间内肯定不会执行；yield()只是使当前线程重新回到可执行状态，所以执行yield()的线程有可能在进入到可执行状态后马上又被执行。Sleep()可使优先级低的线程得到执行的机会，当然也可以让同优先级和高优先级的线程有执行的机会；yield()只能使同优先级的线程有执行的机会。</li>
</ul>
<p><strong>1.5 补充：死锁的概念</strong></p>
<p>死锁：指两个或两个以上的进程（或线程）在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。</p>
<p>死锁产生的四个必要条件（缺一不可）：</p>
<ul>
<li>互斥条件：顾名思义，线程对资源的访问是排他性，当该线程释放资源后下一线程才可进行占用。</li>
<li>请求和保持：简单来说就是自己拿的不放手又等待新的资源到手。线程T1至少已经保持了一个资源R1占用,但又提出对另一个资源R2请求，而此时，资源R2被其他线程T2占用，于是该线程T1也必须等待，但又对自己保持的资源R1不释放。</li>
<li>不可剥夺：在没有使用完资源时，其他线性不能进行剥夺。</li>
<li>循环等待：一直等待对方线程释放资源。</li>
</ul>
<p>我们可以根据死锁的四个必要条件破坏死锁的形成。</p>
<p><strong>1.6 补充：并发和并行的区别</strong></p>
<p>并发：是指在某个时间段内，多任务交替的执行任务。当有多个线程在操作时，把CPU运行时间划分成若干个时间段,再将时间段分配给各个线程执行。在一个时间段的线程代码运行时，其它线程处于挂起状。</p>
<p>并行：是指同一时刻同时处理多任务的能力。当有多个线程在操作时，CPU同时处理这些线程请求的能力。</p>
<p>区别就在于CPU是否能同时处理所有任务，并发不能，并行能。</p>
<p><strong>1.7 补充：线程安全三要素</strong></p>
<ul>
<li>原子性：Atomic包、CAS算法、Synchronized、Lock。</li>
<li>可见性：Synchronized、Volatile（不能保证原子性）。</li>
<li>有序性：Happens-before规则。</li>
</ul>
<p><strong>1.8 补充：如何实现线程安全</strong></p>
<ul>
<li>互斥同步：Synchronized、Lock。</li>
<li>非阻塞同步：CAS。</li>
<li>无需同步的方案：如果一个方法本来就不涉及共享数据，那它自然就无需任何同步操作去保证正确性。</li>
</ul>
<p><strong>1.9 补充：保证线程安全的机制：</strong></p>
<ul>
<li>[Synchronized]关键字</li>
<li>[Lock]</li>
<li>[CAS]、原子变量</li>
<li>[ThreadLocal]：简单来说就是让每个线程，对同一个变量，都有自己的独有副本，每个线程实际访问的对象都是自己的，自然也就不存在线程安全问题了。</li>
<li>[Volatile]</li>
<li>[CopyOnWrite]写时复制</li>
</ul>
<p>随着CPU核心的增多以及互联网迅速发展，单线程的程序处理速度越来越跟不上发展速度和大数据量的增长速度，多线程应运而生，充分利用CPU资源的同时，极大提高了程序处理速度。</p>
<p><strong>创建线程的方法</strong></p>
<p>继承Thread类：</p>
<pre><code>public class ThreadCreateTest {
    public static void main(String\[\] args) {
        new MyThread().start();
    }
}

class MyThread extends Thread {
    @Override
    public void run() {
        System.out.println(Thread.currentThread().getName() + &quot;\\t&quot; + Thread.currentThread().getId());
    }
}
</code></pre>
<p>实现Runable接口：</p>
<pre><code>public class RunableCreateTest {
    public static void main(String\[\] args) {
        MyRunnable runnable = new MyRunnable();
        new Thread(runnable).start();
    }
}

class MyRunnable implements Runnable {
    @Override
    public void run() {
        System.out.println(Thread.currentThread().getName() + &quot;\\t&quot; + Thread.currentThread().getId());
    }
}
</code></pre>
<p>通过Callable和Future创建线程：</p>
<pre><code>public class CallableCreateTest {
    public static void main(String [] args) throws Exception {
         // 将Callable包装成FutureTask，FutureTask也是一种Runnable
        MyCallable callable = new MyCallable();
        FutureTask futureTask = new FutureTask&lt;&gt;(callable);
        new Thread(futureTask).start();

        // get方法会阻塞调用的线程
        Integer sum = futureTask.get();
        System.out.println(Thread.currentThread().getName() + Thread.currentThread().getId() + &quot;=&quot; + sum);
    }
}

class MyCallable implements Callable&lt;Integer&gt; {

    @Override
    public Integer call() throws Exception {
        System.out.println(Thread.currentThread().getName() + &quot;\\t&quot; + Thread.currentThread().getId() + &quot;\\t&quot; + new Date() + &quot; \\tstarting...&quot;);

        int sum = 0;
        for (int i = 0; i &lt;= 100000; i++) {
            sum += i;
        }
        Thread.sleep(5000);

        System.out.println(Thread.currentThread().getName() + &quot;\\t&quot; + Thread.currentThread().getId() + &quot;\\t&quot; + new Date() + &quot; \\tover...&quot;);
        return sum;
    }
}
</code></pre>
<p>线程池方式创建：</p>
<p>实现Runnable接口这种方式更受欢迎，因为这不需要继承Thread类。在应用设计中已经继承了别的对象的情况下，这需要多继承（而Java不支持多继承，但可以多实现啊），只能实现接口。同时，线程池也是非常高效的，很容易实现和使用。</p>
<p><strong>2.1 线程池创建线程</strong></p>
<p>线程池，顾名思义，线程存放的地方。和数据库连接池一样，存在的目的就是为了较少系统开销，主要由以下几个特点：</p>
<p>降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗（主要）。</p>
<p>提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。</p>
<p>提高线程的可管理性。线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性。</p>
<p>Java提供四种线程池创建方式：</p>
<ul>
<li>newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。</li>
<li>newFixedThreadPool创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。</li>
<li>newScheduledThreadPool创建一个定长线程池，支持定时及周期性任务执行。</li>
<li>newSingleThreadExecutor创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序（FIFO, LIFO, 优先级）执行。</li>
</ul>
<p>通过源码我们得知ThreadPoolExecutor继承自AbstractExecutorService，而AbstractExecutorService实现了ExecutorService。</p>
<pre><code>public class ThreadPoolExecutor extends AbstractExecutorService

public abstract class AbstractExecutorService implements ExecutorService
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/473301.png" alt="" loading="lazy"></figure>
<p><strong>2.2 ThreadPoolExecutor介绍</strong></p>
<p>实际项目中，用的最多的就是ThreadPoolExecutor这个类，而《阿里巴巴Java开发手册》中强制线程池不允许使用Executors去创建，而是通过New ThreadPoolExecutor实例的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。</p>
<figure data-type="image" tabindex="4"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/789301.png" alt="img" loading="lazy"></figure>
<p>我们从ThreadPoolExecutor入手多线程创建方式，先看一下线程池创建的最全参数。</p>
<pre><code>public ThreadPoolExecutor(int corePoolSize,
                          int maximumPoolSize,
                          long keepAliveTime,
                          TimeUnit unit,
                          BlockingQueue workQueue,
                          ThreadFactory threadFactory,
                          RejectedExecutionHandler handler) {
    if (corePoolSize &lt; 0 ||
        maximumPoolSize &lt;= 0 ||
        maximumPoolSize &lt; corePoolSize ||
        keepAliveTime &lt; 0)
        throw new IllegalArgumentException();
    if (workQueue == null || threadFactory == null || handler == null)
        throw new NullPointerException();
    this.corePoolSize = corePoolSize;
    this.maximumPoolSize = maximumPoolSize;
    this.workQueue = workQueue;
    this.keepAliveTime = unit.toNanos(keepAliveTime);
    this.threadFactory = threadFactory;
    this.handler = handler;
}
</code></pre>
<p>参数说明如下：</p>
<ul>
<li>corePoolSize：线程池的核心线程数，即便线程池里没有任何任务，也会有corePoolSize个线程在候着等任务。</li>
<li>maximumPoolSize：最大线程数，不管提交多少任务，线程池里最多工作线程数就是maximumPoolSize。</li>
<li>keepAliveTime：线程的存活时间。当线程池里的线程数大于corePoolSize时，如果等了keepAliveTime时长还没有任务可执行，则线程退出。</li>
<li>Unit：这个用来指定keepAliveTime的单位，比如秒：TimeUnit.SECONDS。</li>
<li>BlockingQueue：一个阻塞队列，提交的任务将会被放到这个队列里。</li>
<li>threadFactory：线程工厂，用来创建线程，主要是为了给线程起名字，默认工厂的线程名字：pool-1-thread-3。</li>
<li>handler：拒绝策略，当线程池里线程被耗尽，且队列也满了的时候会调用。</li>
</ul>
<p><strong>2.2.1BlockingQueue</strong></p>
<p>对于BlockingQueue个人感觉还需要单独拿出来说一下。</p>
<p>BlockingQueue：阻塞队列，有先进先出（注重公平性）和先进后出（注重时效性）两种，常见的有两种阻塞队列：ArrayBlockingQueue和LinkedBlockingQueue</p>
<p>队列的数据结构大致如图：</p>
<figure data-type="image" tabindex="5"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/137301.png" alt="img" loading="lazy"></figure>
<p>队列一端进入，一端输出。而当队列满时，阻塞。BlockingQueue核心方法：1. 放入数据put2. 获取数据take。常见的两种Queue：</p>
<p><strong>2.2.2 ArrayBlockingQueue</strong></p>
<p>基于数组实现，在ArrayBlockingQueue内部，维护了一个定长数组，以便缓存队列中的数据对象，这是一个常用的阻塞队列，除了一个定长数组外，ArrayBlockingQueue内部还保存着两个整形变量，分别标识着队列的头部和尾部在数组中的位置。</p>
<p>一段代码来验证一下：</p>
<pre><code>package map;

import java.util.concurrent.*;

public class MyTestMap {
    // 定义阻塞队列大小
    private static final int maxSize = 5;
    public static void main(String\[\] args){
        ArrayBlockingQueue queue = new ArrayBlockingQueue(maxSize);
        new Thread(new Productor(queue)).start();
        new Thread(new Customer(queue)).start();
    }
}

class Customer implements Runnable {
    private BlockingQueue queue;
    Customer(BlockingQueue queue) {
        this.queue = queue;
    }

    @Override
    public void run() {
        this.cusume();
    }

    private void cusume() {
        while (true) {
            try {
                int count = (int) queue.take();
                System.out.println(&quot;customer正在消费第&quot; + count + &quot;个商品===&quot;);
                // 只是为了方便观察输出结果
                Thread.sleep(10);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }
}

class Productor implements Runnable {
    private BlockingQueue queue;
    private int count = 1;
    Productor(BlockingQueue queue) {
        this.queue = queue;
    }

    @Override
    public void run() {
        this.product();
    }
    private void product() {
        while (true) {
            try {
                queue.put(count);
                System.out.println(&quot;生产者正在生产第&quot; + count + &quot;个商品&quot;);
                count++;
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }
}
</code></pre>
<p>输出如下：</p>
<pre><code>生产者正在生产第1个商品
生产者正在生产第2个商品
生产者正在生产第3个商品
生产者正在生产第4个商品
生产者正在生产第5个商品
customer正在消费第1个商品===
</code></pre>
<p><strong>2.2.3 LinkedBlockingQueue</strong></p>
<p>基于链表的阻塞队列，内部也维护了一个数据缓冲队列。需要我们注意的是如果构造一个LinkedBlockingQueue对象，而没有指定其容量大小。</p>
<p>LinkedBlockingQueue会默认一个类似无限大小的容量（Integer.MAX_VALUE），这样的话，如果生产者的速度一旦大于消费者的速度，也许还没有等到队列满阻塞产生，系统内存就有可能已被消耗殆尽了。</p>
<p><strong>2.2.4 LinkedBlockingQueue和ArrayBlockingQueue的主要区别</strong></p>
<ul>
<li>ArrayBlockingQueue的初始化必须传入队列大小，LinkedBlockingQueue则可以不传入。</li>
<li>ArrayBlockingQueue用一把锁控制并发，LinkedBlockingQueue俩把锁控制并发，锁的细粒度更细。即前者生产者消费者进出都是一把锁，后者生产者生产进入是一把锁，消费者消费是另一把锁。</li>
<li>ArrayBlockingQueue采用数组的方式存取，LinkedBlockingQueue用Node链表方式存取。</li>
</ul>
<p><strong>2.2.5handler拒绝策略</strong></p>
<p>Java提供了4种丢弃处理的方法，当然你也可以自己实现，主要是要实现接口：RejectedExecutionHandler中的方法。</p>
<ul>
<li>AbortPolicy：不处理，直接抛出异常。</li>
<li>CallerRunsPolicy：只用调用者所在线程来运行任务，即提交任务的线程。</li>
<li>DiscardOldestPolicy：LRU策略，丢弃队列里最近最久不使用的一个任务，并执行当前任务。</li>
<li>DiscardPolicy：不处理，丢弃掉，不抛出异常。</li>
</ul>
<p><strong>2.2.6线程池五种状态</strong></p>
<pre><code>private static final int RUNNING    = -1 &lt;&lt; COUNT_BITS;
private static final int SHUTDOWN   =  0 &lt;&lt; COUNT_BITS;
private static final int STOP       =  1 &lt;&lt; COUNT_BITS;
private static final int TIDYING    =  2 &lt;&lt; COUNT_BITS;
private static final int TERMINATED =  3 &lt;&lt; COUNT_BITS;
</code></pre>
<p>RUNNING：在这个状态的线程池能判断接受新提交的任务，并且也能处理阻塞队列中的任务。</p>
<p>SHUTDOWN：处于关闭的状态，该线程池不能接受新提交的任务，但是可以处理阻塞队列中已经保存的任务，在线程处于RUNNING状态，调用shutdown()方法能切换为该状态。</p>
<p>STOP：线程池处于该状态时既不能接受新的任务也不能处理阻塞队列中的任务，并且能中断现在线程中的任务。当线程处于RUNNING和SHUTDOWN状态，调用shutdownNow()方法就可以使线程变为该状态。</p>
<p>TIDYING：在SHUTDOWN状态下阻塞队列为空，且线程中的工作线程数量为0就会进入该状态，当在STOP状态下时，只要线程中的工作线程数量为0就会进入该状态。</p>
<p>TERMINATED：在TIDYING状态下调用terminated()方法就会进入该状态。可以认为该状态是最终的终止状态。</p>
<p>回到线程池创建ThreadPoolExecutor，我们了解了这些参数，再来看看ThreadPoolExecutor的内部工作原理：</p>
<figure data-type="image" tabindex="6"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/378301.png" alt="" loading="lazy"></figure>
<ul>
<li>判断核心线程是否已满，是进入队列，否：创建线程</li>
<li>判断等待队列是否已满，是：查看线程池是否已满，否：进入等待队列</li>
<li>查看线程池是否已满，是：拒绝，否创建线程</li>
</ul>
<p><strong>2.3深入理解ThreadPoolExecutor</strong></p>
<p>进入Execute方法可以看到：</p>
<pre><code>public void execute(Runnable command) {
    if (command == null)
        throw new NullPointerException();
    int c = ctl.get();
  //判断当前活跃线程数是否小于corePoolSize,如果小于，则调用addWorker创建线程执行任务
    if (workerCountOf(c) &lt; corePoolSize) {
        if (addWorker(command, true))
            return;
        c = ctl.get();
    }
  //如果不小于corePoolSize，则将任务添加到workQueue队列。
    if (isRunning(c) &amp;&amp; workQueue.offer(command)) {
        int recheck = ctl.get();
        if (! isRunning(recheck) &amp;&amp; remove(command))
            reject(command);
        else if (workerCountOf(recheck) == 0)
            addWorker(null, false);
    }
  //如果放入workQueue失败，则创建线程执行任务，如果这时创建线程失败(当前线程数不小于maximumPoolSize时)，就会调用reject(内部调用handler)拒绝接受任务。
    else if (!addWorker(command, false))
        reject(command);
}
</code></pre>
<p>AddWorker方法：</p>
<ul>
<li>创建Worker对象，同时也会实例化一个Thread对象。在创建Worker时会调用threadFactory来创建一个线程。</li>
<li>然后启动这个线程。</li>
</ul>
<p><strong>2.3.1线程池中CTL属性的作用是什么？</strong></p>
<p>CTL属性包含两个概念：</p>
<pre><code>private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));
private static int ctlOf(int rs, int wc) { return rs | wc; }
</code></pre>
<ul>
<li>runState：即rs 表明当前线程池的状态，是否处于Running，Shutdown，Stop，Tidying。</li>
<li>workerCount：即wc表明当前有效的线程数。</li>
</ul>
<p>我们点击workerCount即工作状态记录值，以RUNNING为例，RUNNING = -1 &lt;&lt;  COUNT_BITS;，即-1无符号左移COUNT_BITS位，进一步我们得知COUNT_BITS位29，因为Integer位数为31位（2的五次方减一）</p>
<pre><code>private static final int COUNT_BITS = Integer.SIZE - 3;
</code></pre>
<p>既然是29位那么就是Running的值为：</p>
<pre><code>1110 0000 0000 0000 0000 0000 0000 0000
|||
31~29位
</code></pre>
<p>那低28位呢，就是记录当前线程的总线数啦：</p>
<pre><code>// Packing and unpacking ctl
private static int runStateOf(int c)     { return c &amp; ~CAPACITY; }
private static int workerCountOf(int c)  { return c &amp; CAPACITY; }
private static int ctlOf(int rs, int wc) { return rs | wc; }
</code></pre>
<p>从上述代码可以看到workerCountOf这个函数传入ctl之后，是通过CTL&amp;CAPACITY操作来获取当前运行线程总数的。</p>
<p>也就是RunningState|WorkCount&amp;CAPACITY，算出来的就是低28位的值。因为CAPACITY得到的就是高3位（29-31位）位0，低28位（0-28位）都是1，所以得到的就是ctl中低28位的值。</p>
<p>而runStateOf这个方法的话，算的就是RunningState|WorkCount&amp;CAPACITY，高3位的值，因为CAPACITY是CAPACITY的取反，所以得到的就是高3位（29-31位）为1，低28位（0-28位）为0，所以通过&amp;运算后，所得到的值就是高3为的值。</p>
<p>简单来说就是ctl中是高3位作为状态值，低28位作为线程总数值来进行存储。</p>
<p><strong>2.3.2 shutdownNow和shutdown的区别</strong></p>
<p>看源码发现有两种近乎一样的方法，shutdownNow和shutdown，设计者这么设计自然是有它的道理，那么这两个方法的区别在哪呢？</p>
<ul>
<li>shutdown会把线程池的状态改为SHUTDOWN，而shutdownNow把当前线程池状态改为STOP。</li>
<li>shutdown只会中断所有空闲的线程，而shutdownNow会中断所有的线程。</li>
<li>shutdown返回方法为空，会将当前任务队列中的所有任务执行完毕；而shutdownNow把任务队列中的所有任务都取出来返回。</li>
</ul>
<p><strong>2.3.3 线程复用原理</strong></p>
<pre><code>final void runWorker(Worker w) {
    Thread wt = Thread.currentThread();
    Runnable task = w.firstTask;
    w.firstTask = null;
    w.unlock(); // allow interrupts
    boolean completedAbruptly = true;
    try {
        while (task != null || (task = getTask()) != null) {
            w.lock();
            // If pool is stopping, ensure thread is interrupted;
            // if not, ensure thread is not interrupted.  This
            // requires a recheck in second case to deal with
            // shutdownNow race while clearing interrupt
            if ((runStateAtLeast(ctl.get(), STOP) ||
                 (Thread.interrupted() &amp;&amp;
                  runStateAtLeast(ctl.get(), STOP))) &amp;&amp;
                !wt.isInterrupted())
                wt.interrupt();
            try {
                beforeExecute(wt, task);
                Throwable thrown = null;
                try {
                    task.run();
                } catch (RuntimeException x) {
                    thrown = x; throw x;
                } catch (Error x) {
                    thrown = x; throw x;
                } catch (Throwable x) {
                    thrown = x; throw new Error(x);
                } finally {
                    afterExecute(task, thrown);
                }
            } finally {
                task = null;
                w.completedTasks++;
                w.unlock();
            }
        }
        completedAbruptly = false;
    } finally {
        processWorkerExit(w, completedAbruptly);
    }
}
</code></pre>
<p>就是任务在并不只执行创建时指定的firstTask第一任务，还会从任务队列的中自己主动取任务执行，而且是有或者无时间限定的阻塞等待，以保证线程的存活。</p>
<p>默认的是不允许。</p>
<p><strong>2.4 CountDownLatch和CyclicBarrier区别</strong></p>
<p>countDownLatch是一个计数器，线程完成一个记录一个，计数器递减，只能只用一次。</p>
<p>CyclicBarrier的计数器更像一个阀门，需要所有线程都到达，然后继续执行，计数器递增，提供Reset功能，可以多次使用。</p>
<p><strong>3. 多线程间通信的几种方式</strong></p>
<p>提及多线程又不得不提及多线程通信的机制。首先，要短信线程间通信的模型有两种：共享内存和消息传递，以下方式都是基本这两种模型来实现的。我们来基本一道面试常见的题目来分析：</p>
<p>题目：有两个线程A、B，A线程向一个集合里面依次添加元素”abc”字符串，一共添加十次，当添加到第五次的时候，希望B线程能够收到A线程的通知，然后B线程执行相关的业务操作。</p>
<p><strong>3.1使用volatile关键字</strong></p>
<pre><code>package thread;

/**
 *
 * @author hxz
 * @description 多线程测试类
 * @version 1.0
 * @data 2020年2月15日 上午9:10:09
 */
public class MyThreadTest {

    public static void main(String\[\] args) throws Exception {

        notifyThreadWithVolatile();

    }

    /**
     * 定义一个测试
     */
    private static volatile boolean flag = false;
    /**
     * 计算I++，当I==5时，通知线程B
     * @throws Exception
     */
    private static void notifyThreadWithVolatile() throws Exception {
        Thread thc = new Thread(&quot;线程A&quot;){
            @Override
            public void run() {
                for (int i = 0; i &lt; 10; i++) {
                    if (i == 5) {
                        flag = true;
                        try {
                            Thread.sleep(500L);
                        } catch (InterruptedException e) {
                            // TODO Auto-generated catch block
                            e.printStackTrace();
                        }
                        break;
                    }
                    System.out.println(Thread.currentThread().getName() + &quot;====&quot; + i);
                }
            }
        };

        Thread thd = new Thread(&quot;线程B&quot;) {
            @Override
            public void run() {
                while (true) {
                    // 防止伪唤醒 所以使用了while
                    while (flag) {
                        System.out.println(Thread.currentThread().getName() + &quot;收到通知&quot;);
                        System.out.println(&quot;do something&quot;);
                        try {
                            Thread.sleep(500L);
                        } catch (InterruptedException e) {
                            // TODO Auto-generated catch block
                            e.printStackTrace();
                        }
                        return ;
                    }

                }
            }
        };

        thd.start();
        Thread.sleep(1000L);
        thc.start();

    }
}
</code></pre>
<p>个人认为这是基本上最好的通信方式，因为A发出通知B能够立马接受并Do Something。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[使用Springboot+mockito进行单元测试]]></title>
        <id>https://kangjn.github.io/post/shi-yong-springbootmockito-jin-xing-dan-yuan-ce-shi/</id>
        <link href="https://kangjn.github.io/post/shi-yong-springbootmockito-jin-xing-dan-yuan-ce-shi/">
        </link>
        <updated>2021-04-21T08:13:18.000Z</updated>
        <content type="html"><![CDATA[<p>​    <strong>简介：</strong>  ## SpringBoot应用测试 测试Springboot应用需要依赖一个非常重要的注解@SpringBootTest，这个注解会为测试用例构建Spring容器。@SpringBootTest注解修饰的测试用例默认不会启动web容器，如果需要启动web容器需要设置webEnvironment属性： * MOCK(默认)：会启动一个mock的web server，可以配合@AutoConfig</p>
<h2 id="springboot应用测试">SpringBoot应用测试</h2>
<p>测试Springboot应用需要依赖一个非常重要的注解@SpringBootTest，这个注解会为测试用例构建Spring容器。@SpringBootTest注解修饰的测试用例默认不会启动web容器，如果需要启动web容器需要设置webEnvironment属性：</p>
<ul>
<li>MOCK(默认)：会启动一个mock的web server，可以配合@AutoConfigureMockMvc注解对web应用进行测试(后面会举例)</li>
<li>RANDOM_PORT：创建ApplicationContext上下文，启动一个真实的Web容器，监听一个随机的端口。</li>
<li>DEFINED_PORT：创建ApplicationContext上下文，启动一个真实的Web容器，监听SpringBoot配置配置文件中指定的端口，默认是8080端口。</li>
<li>NONE：只是启动ApplicationContext，不会启动任何(Mock或者非Mock)web容器。</li>
</ul>
<p>如果是使用Junit来进行单元测试，再增加一个@RunWith(SpringRunner.class)或者@RunWith(SpringJUnit4ClassRunner.class)注解。</p>
<h2 id="利用模拟web容器来测试restful接口">利用模拟Web容器来测试Restful接口</h2>
<p>当测试用例使用@SpringBootTest注解修饰并将webEnvironment属性设置MOCK之后，测试用例在执行的过程中，就会创建一个模拟的web容器。为了让测试用例能够访问这个模拟的web容器，还需要增加@AutoConfigureMockMvc注解，这样就可以把MockMvc对象利用@Autowired注解注入到测试用例的属性中。MockMvc类的作用就是可以访问模拟的Web容器。接下来我们看一下使用MockMvc配合MockMvcRequestBuilders及MockMvcResultMatchers来访问模拟的Web容器进行测试Rest接口的例子：</p>
<ul>
<li>GET请求</li>
</ul>
<pre><code>    @Test
    public void testCase() throws Exception {
        MvcResult result = mvc.perform(MockMvcRequestBuilders.get(&quot;/testQueryData.json?id=6&quot;))
                .andExpect(
                        MockMvcResultMatchers.status().isOk()).andReturn();
       Assert.assertNotNull(result.getResponse().getContentAsString());
    }
</code></pre>
<ul>
<li>POST请求提交表单</li>
</ul>
<pre><code>    @Test
    public void testCase() throws Exception {
        UrlEncodedFormEntity formData = new UrlEncodedFormEntity(Arrays.asList(
                new BasicNameValuePair(&quot;param1&quot;, &quot;xxxxxxx&quot;),
                new BasicNameValuePair(&quot;param2&quot;, &quot;xxxxxxx&quot;)
        ), &quot;utf-8&quot;);
        MvcResult result = mvc.perform(MockMvcRequestBuilders.post(&quot;/testPostData.json&quot;)
                .contentType(MediaType.APPLICATION_FORM_URLENCODED_VALUE)
          .content(EntityUtils.toString(formData))).andExpect(MockMvcResultMatchers.status().isOk()).andReturn();
        Assert.assertNotNull(result.getResponse().getContentAsString());
    }
</code></pre>
<ul>
<li>DELETE请求</li>
</ul>
<pre><code>    @Test
    public void testCase() throws Exception {
        mvc.perform(MockMvcRequestBuilders.delete(&quot;/testDeleteData.json?id=1&quot;))
                .andExpect(
                        MockMvcResultMatchers.status().isOk());
    }
</code></pre>
<ul>
<li>PUT请求类似POST</li>
</ul>
<pre><code>    @Test
    public void testCase() throws Exception {
        MvcResult result = mvc.perform(MockMvcRequestBuilders.put(&quot;/testPutData&quot;))
                .andExpect(
                        MockMvcResultMatchers.status().isOk()).andReturn();
        Assert.assertNotNull(result.getResponse().getContentAsString());
    }
</code></pre>
<h2 id="利用testresttemplate测试真实的restful接口">利用TestRestTemplate测试真实的Restful接口</h2>
<p>Springboot提供了专门用来测试Restful接口的工具类TestRestTemplate，这个类对RestTemplate进行了封装，可以让用户很快捷的编写出http客户端测试代码。<br>
实例如下：</p>
<ul>
<li>GET请求</li>
</ul>
<pre><code>public void testCase() throws Exception {
  String restUrl = &quot;http://localhost:8080/xxxxx/xxxxx.json?id=xxx&quot;;
  ResponseEntity&lt;RegcoreResp&gt; response = testRestTemplate.getForEntity(restUrl, RegcoreResp.class);    //RegcoreResp是用户自行定义的返回的数据封装Bean，
  System.out.println(response.getBody());
}
</code></pre>
<ul>
<li>POST请求并采用表单方式提交数据</li>
</ul>
<pre><code>public void testCase() throws Exception {
String restUrl = &quot;http://localhost:8080/xxxxx/xxxxx.json&quot;;
        HttpHeaders headers = new HttpHeaders();
        headers.setContentType(MediaType.APPLICATION_FORM_URLENCODED);
        MultiValueMap&lt;String, String&gt; params = new LinkedMultiValueMap&lt;String, String&gt;();
        params.add(&quot;name&quot;, &quot;testName&quot;); 
        HttpEntity&lt;MultiValueMap&lt;String, String&gt;&gt; requestEntity = new HttpEntity&lt;MultiValueMap&lt;String, String&gt;&gt;(params, headers);
        ResponseEntity&lt;RegcoreResp&gt; response = testRestTemplate.postForEntity(restUrl, requestEntity, RegcoreResp.class);
}
</code></pre>
<ul>
<li>POST请求并采用request Body方式传输数据</li>
</ul>
<pre><code>public void testCase() throws Exception {
        String restUrl = &quot;http://localhost:8080/xxxxx/xxxxx.json&quot;;
        HttpHeaders headers = new HttpHeaders();
        headers.setContentType(MediaType.APPLICATION_JSON);
        String body = &quot;{\&quot;id\&quot;:\&quot;xxxxxx\&quot;,\&quot;status\&quot;:\&quot;xxxxx\&quot;}&quot;;
        HttpEntity&lt;String&gt; requestEntity = new HttpEntity&lt;String&gt;(body, headers);
        ResponseEntity&lt;BaseFacadeResp&gt; response = testRestTemplate.postForEntity(restUrl, requestEntity, BaseFacadeResp.class);
}
</code></pre>
<ul>
<li>DELETE</li>
</ul>
<pre><code>public void testCase() throws Exception {
        String restUrl = &quot;http://localhost:8080/xxxxx/xxxxx.json&quot;;
        testRestTemplate.delete(restUrl);  //delete方法没有返回值
}
</code></pre>
<ul>
<li>PUT方式与POST类似</li>
</ul>
<pre><code>public void testCase() throws Exception {
        String restUrl = &quot;http://localhost:8080/xxxxx/xxxxx.json&quot;;
        HttpHeaders headers = new HttpHeaders();
        headers.setContentType(MediaType.APPLICATION_JSON);
        String body = &quot;{\&quot;id\&quot;:\&quot;xxxxxx\&quot;,\&quot;status\&quot;:\&quot;xxxxx\&quot;}&quot;;
        HttpEntity&lt;String&gt; requestEntity = new HttpEntity&lt;String&gt;(body, headers);
        testRestTemplate.put(restUrl, requestEntity);  //put方法没有返回值
}
</code></pre>
<h2 id="mock与spy">Mock与Spy</h2>
<ul>
<li>Mock利用动态代理对一个接口或者类的所有方法进行模拟。</li>
<li>Spy同样利用动态代理，与Mock不同的是Spy针对于一个真实对象进行模拟并可以对被监控对象中某个方法进行打桩(stubed)控制该方法的执行情况，其他没有打桩的方法则按照对象本身的实际逻辑执行。</li>
</ul>
<h2 id="springboot对mock-spy的支持">SpringBoot对Mock Spy的支持</h2>
<p>在测试SpringBoot应用过程中，某些环境依赖问题可能导致无法调用真实Bean逻辑，比如：某些外部依赖的接口没有准备好。这个时候需要使用Mock、Spy来对Bean进行模拟。SpringBoot提供了@MockBean和@SpyBean两个注解来实现Mock与Spy能力。由于底层还是使用Mockito，用法上与Mockito没有区别。<br>
示例：</p>
<pre><code>@RunWith(SpringRunner.class) @SpringBootTest
public class MyTests {
  @MockBean
  private RemoteService remoteService; 
  @Autowired
  private Reverser reverser;
  @Test
  public void exampleTest() {
    // RemoteService has been injected into the reverser bean 
    given(this.remoteService.someCall()).willReturn(&quot;mock&quot;); 
    String reverse = reverser.reverseSomeCall(); 
    assertThat(reverse).isEqualTo(&quot;kcom&quot;);
  }
}
</code></pre>
<h2 id="如何mock方法模拟内部逻辑">如何Mock方法模拟内部逻辑?</h2>
<p>一般来说mock最典型的用法就是对一个方法的返回值(输出)进行模拟。如果想模拟方法内部逻辑，比如方法对入参进行修改或者对入参对象的某个方法进行回调如何利用mock来实现呢？<br>
下面举一个实际的场景，比如有这样一段被测试代码：</p>
<pre><code>  testDOMapper.insert(testBeanDO);
  if(testBeanDO.getId()==null) {
       throw new RuntimeException();
  }
</code></pre>
<p>插入数据之后数据库中新纪录的id会回填到templateDO.id这个属性，这个特性是mybatis的一种常用的用法。但是如果我们用Mock如果来实现测试代码执行过testDOMapper.insert(templateDO)之后将templateDO.id属性附上值，如何实现呢？这里要用Answer这个接口</p>
<pre><code>       Mockito.when(testDOMapper.insert(Mockito.any(TestBeanDO.class))).thenAnswer(new 
          Answer&lt;Integer&gt;() {
            @Override
            public Integer answer(InvocationOnMock invocation) throws Throwable {
                TestBeanDO arg = invocation.getArgumentAt(0, TestBeanDO.class);
                arg.setId(1L);
                return 1;
            }
        });
</code></pre>
<p>上面的代码可以看到answer可以模拟调用insert()方法时方法体如何执行。answer的入参InvocationOnMock对象可以获取实际的入参的对象，这样只要在answer方法体里对入参属性进行修改就可以实现我们想要达到的效果了。<br>
类似的方法还可以使用 ArgumentMatcher 来实现对参数进行捕获修改，这里给出示例就不再具体说明了。</p>
<pre><code>        Mockito.when(testDOMapper.insert(Mockito.argThat(new ArgumentMatcher&lt;TestBeanDO&gt;() {
            @Override
            public boolean matches(Object argument) {
                ((TestBeanDO) argument).setId(1L);
                return true;
            }
        }))).thenReturn(1);
</code></pre>
<h2 id="给spy的对象进行打桩">给Spy的对象进行打桩</h2>
<p>spy一般对监控一个真实的对象，按照之前mock的常见用法：</p>
<pre><code>Mockito.when(spyObj.method()).thenReturn(xxxx);  
</code></pre>
<p>其实是不会按照thenReturn()指定的结果返回的，这一点要特别的注意，容易采坑。如果想按照用户自己的定义对spy对象进行打桩的正确方式是：</p>
<pre><code>Mockito.doReturn(xxxx).when(sypObj).method();
</code></pre>
<p>提前设置好方法被调用之后的表现doReturn()返回结果还是doThrow()抛出异常，之后再使用when(spyObj)对spy的对象进行包装之后设置调用的方法就可以了。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[了解Java异步编程]]></title>
        <id>https://kangjn.github.io/post/liao-jie-java-yi-bu-bian-cheng/</id>
        <link href="https://kangjn.github.io/post/liao-jie-java-yi-bu-bian-cheng/">
        </link>
        <updated>2021-04-21T07:14:33.000Z</updated>
        <content type="html"><![CDATA[<h3 id="了解java异步编程">了解Java异步编程</h3>
<p>随着<code>RxJava</code>、<code>Reactor</code>等异步框架的流行，异步编程受到了越来越多的关注，尤其是在IO密集型的业务场景中，相比传统的同步开发模式，异步编程的优势越来越明显。</p>
<p>那到底什么是异步编程？异步化真正的好处又是什么？如何选择适合自己团队的异步技术？在实施异步框架落地的过程中有哪些需要注意的地方？</p>
<ol>
<li>使用RxJava异步改造后的效果</li>
<li>什么是异步编程？异步实现原理</li>
<li>异步技术选型参考</li>
<li>异步化真正的好处是什么？</li>
<li>异步化落地的难点及解决方案</li>
<li>扩展:异步其他解决方案-协程</li>
</ol>
<h2 id="使用rxjava异步改造后的效果">使用RxJava异步改造后的效果</h2>
<p>下图是我们后端java项目使用RxJava改造成异步前后的RT(响应时长)效果对比：</p>
<figure data-type="image" tabindex="1"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/164025.png" alt="img" loading="lazy"></figure>
<figure data-type="image" tabindex="2"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/164040.png" alt="img" loading="lazy"></figure>
<p>统计数据基于App端的gateway，以75线为准，还有80、85、90、99线，从图中可以看出改成异步后接口整体的平均响应时长降低了**40%**左右。</p>
<p>(响应时间是以发送请求到收到后端接口响应数据的时长，上图改造的这个后端java接口内部流程比较复杂，因为公司都是微服务架构，该接口内部又调用了6个其他服务的接口，最后把这些接口的数据汇总在一起返回给前端)</p>
<p>这张图是同步接口和改造成异步接口前后的CPU负载情况对比</p>
<p>改造前cpu load : 35.46</p>
<figure data-type="image" tabindex="3"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/165003.png" alt="img" loading="lazy"></figure>
<p>改造后cpu load : 14.25</p>
<figure data-type="image" tabindex="4"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/165002.png" alt="img" loading="lazy"></figure>
<p>改成异步后CPU的负载情况也有明显下降，但CPU使用率并无影响(一般情况下异步化后cpu的利用率会有所提高，但要看具体的业务场景)</p>
<p>CPU LoadAverage是指：一段时间内处于可运行状态和不可中断状态的进程平均数量。(可运行分为正在运行进程和正在等待CPU的进程；<strong>不可中断则是它正在做某些工作不能被中断比如等待磁盘IO、网络IO等</strong>)</p>
<p>而我们的服务业务场景大部分都是IO密集型业务，功能实现很多需要依赖底层接口，会进行频繁的IO操作。</p>
<p>下图是2019年在全球架构师峰会上<strong>阿里</strong>分享的异步化改造后的RT和QPS效果：</p>
<figure data-type="image" tabindex="5"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/170052.png" alt="img" loading="lazy"></figure>
<h2 id="什么是异步编程">什么是异步编程？</h2>
<h3 id="响应式编程-nio">响应式编程 + NIO</h3>
<h3 id="1-异步和同步的区别">1. 异步和同步的区别：</h3>
<p>我们先从<strong>I/O</strong>的角度看下同步模式下接口A调用接口B的交互流程:</p>
<p>下图是传统的同步模式下io线程的交互流程，可以看出io是阻塞的，即bio的运行模式</p>
<figure data-type="image" tabindex="6"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/171309.png" alt="img" loading="lazy"></figure>
<p>接口A发起调用接口B后，这段时间什么事情也不能做，主线程阻塞一直等到接口B数据返回，然后才能进行其他操作，可想而知如果接口A调用的接口不止B的话(A-&gt;B-&gt;C-&gt;D-&gt;E。。。)，那么等待的时间也是递增的，而且<strong>这期间CPU也要一直占用着</strong>，白白浪费资源，也就是上图看到的 cpu load 高的原因。</p>
<p>而且还有一个隐患就是如果调用的其他服务中的接口比如C超时，或接口C挂掉了，那么对调用方服务A来说，剩余的接口比如D、E都会无限等待下去。。。</p>
<p>其实大部分情况下我们收到数据后内部的处理逻辑耗时都很短，这个可以通过埋点执行时间统计，<strong>大部分时间都浪费在了IO等待上</strong>。</p>
<p>下面这个视频演示了同步模式下我们线上环境真实的接口调用情况，即接口调用的线程执行和变化情况，(使用的工具是JDK自带的jvisual来监控线程变化情况)</p>
<p>这里先交代下大致背景：服务端api接口A内部一共调用了6个其他服务的接口，大致交互是这样的：</p>
<p>A接口（B -&gt; C -&gt; D -&gt; E -&gt; F -&gt; G）返回聚合数据</p>
<p>背景：使用Jemter测试工具压测100个线程并发请求接口，以观察线程的运行情况（可以全屏观看）：</p>
<p><code>http-nio-8080-exec*</code>开头的是tomcat线程池中的线程，即前端请求我们后端接口时要通过tomcat服务器接收和转发的线程，因为我们后端api接口内部又调用了其他服务的6个接口（B、C、D、E、F、G），同步模式下需要等待上一个接口返回数据才能继续调用下一个接口，所以可以从视频中看出，大部分的http线程耗时都在8秒以上(绿色线条代表线程是”运行中”状态，8秒包括等待接口返回的时间和我们内部逻辑处理的总时间，因为是本地环境测试，受机器和网络影响较大)</p>
<p>然后我们再看下异步模式的交互流程，即nio方式：</p>
<figure data-type="image" tabindex="7"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/182257.png" alt="img" loading="lazy"></figure>
<p>大致流程就是接口A发起调用接口B的请求后就立即返回，而不用阻塞等待接口B响应，这样的好处是<code>http-nio-8080-exec*</code>线程可以<strong>马上得到复用，接着处理下一个前端请求的任务</strong>，如果接口B处理完返回数据后，会有一个回调线程池处理真正的响应，即这种模式下我们的业务流程是<strong>http线程只处理请求，回调线程处理接口响应</strong>。</p>
<p>nio模式下虽然<code>http-nio-8080-exec*</code>线程和回调线程<code>AsfThread-executor-*</code>的运行时间都很短，但是从http线程开始到asf回调处理完返回给前端结果的时间和bio即同步模式下的时间差异不大（在相同的逻辑流程下），并不是nio模式下服务响应的整体时间就会缩短，而是<strong>会提升****CPU的利用率</strong>，因为CPU不再会阻塞等待（不可中断状态减少），这样<strong>CPU就能有更多的资源来处理其他的请求任务</strong>，相同单位时间内能处理更多的任务，所以nio模式带来的好处是：</p>
<ul>
<li><strong>提升QPS（用更少的线程资源实现更高的并发能力）</strong></li>
<li><strong>降低CPU负荷,提高利用率</strong></li>
</ul>
<h3 id="2-nio原理">2. Nio原理</h3>
<figure data-type="image" tabindex="8"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/161708.png" alt="img" loading="lazy"></figure>
<p>结合上面的接口交互图可知，接口B通过网络返回数据给调用方(接口A)这一过程，对应底层实现就是网卡接收到返回数据后，通过自身的DMA（直接内存访问）将数据拷贝到内核缓冲区，这一步不需要CPU参与操作，也就是把原先CPU等待的事情交给了底层网卡去处理，这样<strong>CPU就可以专注于我们的应用程序即接口内部的逻辑运算</strong>。</p>
<h3 id="3-nio-in-java">3. Nio In Java</h3>
<figure data-type="image" tabindex="9"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/212141.png" alt="img" loading="lazy"></figure>
<p>nio在java里的实现主要是上图中的几个核心组件：<code>channel</code>、<code>buffer</code>、<code>selector</code>，这些组件组合起来即实现了上面所讲的<strong>多路复用机制</strong>，如下图所示：</p>
<figure data-type="image" tabindex="10"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/212733.png" alt="img" loading="lazy"></figure>
<h2 id="响应式编程">响应式编程</h2>
<h3 id="1-什么是响应式编程它和传统的编程方式有什么区别">1. 什么是响应式编程？它和传统的编程方式有什么区别？</h3>
<p>响应式可以简单的理解为收到某个事件或通知后采取的一系列动作，如上文中所说的响应操作系统的网络数据通知，然后以<strong>回调的方式</strong>处理数据。</p>
<p>传统的命令式编程主要由：顺序、分支、循环 等控制流来完成不同的行为</p>
<p>响应式编程的特点是：</p>
<ul>
<li><strong>以逻辑为中心转换为以数据为中心</strong></li>
<li><strong>从命令式到声明式的转换</strong></li>
</ul>
<h3 id="2-javautilconcurrentfuture">2. Java.Util.Concurrent.Future</h3>
<p>在Java使用nio后无法立即拿到真实的数据，而且先得到一个”<code>future</code>“，可以理解为邮戳或快递单，为了获悉真正的数据我们需要不停的通过快递单号查询快递进度，所以 <strong>J.U.C 中的 Future 是Java对异步编程的第一个解决方案</strong>，通常和线程池结合使用，伪代码形式如下：</p>
<pre><code>ExecutorService executor = Executors.newCachedThreadPool(); // 线程池
Future&lt;String&gt; future = executor.submit(() -&gt;{
    Thread.sleep(200); // 模拟接口调用，耗时200ms
    return &quot;hello world&quot;;
});
// 在输出下面异步结果时主线程可以不阻塞的做其他事情
// TODO 其他业务逻辑

System.out.println(&quot;异步结果:&quot;+future.get()); //主线程获取异步结果
</code></pre>
<p><code>Future</code>的缺点很明显：</p>
<ul>
<li>无法方便得知任务何时完成</li>
<li>无法方便获得任务结果</li>
<li>在主线程获得任务结果会导致主线程阻塞</li>
</ul>
<h3 id="3-listenablefuture">3. ListenableFuture</h3>
<p>Google并发包下的<code>listenableFuture</code>对Java原生的future做了扩展，顾名思义就是使用监听器模式实现的<strong>回调机制</strong>，所以叫可监听的future。</p>
<pre><code>Futures.addCallback(listenableFuture, new FutureCallback&lt;String&gt;() {
    @Override
    public void onSuccess(String result) {
        System.out.println(&quot;异步结果:&quot; + result);
    }

    @Override
    public void onFailure(Throwable t) {
        t.printStackTrace();
    }
}, executor);
</code></pre>
<p>回调机制的最大问题是：<strong>Callback Hell（回调地狱）</strong></p>
<ul>
<li>代码的字面形式和其所表达的业务含义不匹配</li>
<li>业务的先后关系在代码层面变成了包含和被包含的关系</li>
<li>大量使用 Callback 机制，使应该是先后的业务逻辑在代码形式上表现为层层嵌套,这会导致代码难以理解和维护。</li>
</ul>
<p>那么如何解决 Callback Hell 问题呢？</p>
<p><strong>响应式编程</strong></p>
<p>其实主要是以下两种解决方式：</p>
<ul>
<li>事件驱动机制</li>
<li>链式调用(Lambda)</li>
</ul>
<h3 id="4-completablefuture">4. CompletableFuture</h3>
<p>Java8里的<code>CompletableFuture</code>和Java9的<code>Flow Api</code>勉强算是上面问题的解决方案：</p>
<pre><code>CompletableFuture&lt;String&gt; f1 = CompletableFuture.supplyAsync(() -&gt;
    &quot;hello&quot;
);
// f2依赖f1的结果做转换
CompletableFuture&lt;String&gt; f2 = f1.thenApplyAsync(t -&gt;
    t + &quot; world&quot;
);
System.out.println(&quot;异步结果:&quot; + f2.get());
</code></pre>
<p>但<code>CompletableFuture</code>处理简单的任务可以使用，但并不是一个完整的反应式编程解决方案，在服务调用复杂的情况下，存在服务编排、上下文传递、柔性限流(背压)方面的不足</p>
<p>如果使用<code>CompletableFuture</code>面对这些问题可能需要自己额外造一些轮子，Java9的<code>Flow</code>虽然是基于 <strong>Reactive Streams</strong> 规范实现的，但没有RxJava、Project Reactor这些异步框架丰富和强大和完整的解决方案。</p>
<p>当然如果接口逻辑比较简单，完全可以使用<code>listenableFuture</code>或<code>CompletableFuture</code></p>
<h3 id="5-reactive-streams">5. Reactive Streams</h3>
<p>在网飞推出RxJava1.0并在Android端普及流行开后，响应式编程的规范也呼之欲出：</p>
<p>包括后来的RxJava2.0、Project Reactor都是基于Reactive Streams规范实现的。</p>
<p>关于他们和<code>listenableFuture</code>、 <code>CompletableFuture</code>的区别通过下面的例子大家应该就会清楚。</p>
<p>比如下面的基于回调的代码示例：获取用户的5个收藏列表功能</p>
<figure data-type="image" tabindex="11"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/225236.png" alt="img" loading="lazy"></figure>
<p>图中标注序号的步骤对应如下：</p>
<ol>
<li>根据uid调用用户收藏列表接口<code>userService.getFavorites</code></li>
<li>成功的回调逻辑</li>
<li>如果用户收藏列表为空</li>
<li>调用推荐服务<code>suggestionService.getSuggestions</code></li>
<li>推荐服务成功后的回调逻辑</li>
<li>取前5条推荐并展示(<code>Java8 Stream api</code>)</li>
<li>推荐服务失败的回调,展示错误信息</li>
<li>如果用户收藏列表有数据返回</li>
<li>取前5条循环调用详情接口<code>favoriteService.getDetails</code> 成功回调则展示详情,失败回调则展示错误信息</li>
</ol>
<p>可以看出主要逻辑都是在回调函数（<code>onSuccess()</code>、<code>onError()</code>）中处理的，在可读性和后期维护成本上比较大。</p>
<p>基于Reactive Streams规范实现的响应式编程解决方案如下：</p>
<figure data-type="image" tabindex="12"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/225814.png" alt="img" loading="lazy"></figure>
<ol>
<li>调用用户收藏列表接口</li>
<li>压平数据流调用详情接口</li>
<li>如果收藏列表为空调用推荐接口</li>
<li>取前5条</li>
<li>切换成异步线程处理上述声明接口返回结果)</li>
<li>成功则展示正常数据,错误展示错误信息</li>
</ol>
<p>可以看出因为这些异步框架提供了丰富的api，所以我们可以把主要精力<strong>放在数据的流转上，而不是原来的逻辑控制上。这也是异步编程带来的思想上的转变。</strong></p>
<p>下图是RxJava的<code>operator api</code>：</p>
<figure data-type="image" tabindex="13"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/230605.png" alt="img" loading="lazy"></figure>
<p>（如果这些操作符满足不了你的需求，你也可以自定义操作符）</p>
<p>所以说<strong>异步最吸引人的地方在于资源的充分利用，不把资源浪费在等待的时间上(nio)，代价是增加了程序的复杂度，而Reactive Program封装了这些复杂性，使其变得简单。</strong></p>
<p>所以我们无论使用哪种异步框架，尽量使用框架提供的api，而不是像上图那种基于回调业务的代码，把业务逻辑都写在onSuccess、onError等回调方法里，这样无法发挥异步框架的真正作用：</p>
<blockquote>
<p>Codes Like Sync，Works Like Async</p>
</blockquote>
<p>即以<strong>同步的方式编码，达到异步的效果与性能,兼顾可维护性与可伸缩性</strong>。</p>
<h2 id="异步框架技术选型">异步框架技术选型</h2>
<figure data-type="image" tabindex="14"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/231752.png" alt="img" loading="lazy"></figure>
<p>如果是我个人更愿意选择Project Reactor作为首选异步框架，，还有一点是因为Netflix推出的开源产品渐渐都不维护了，而且Project Reactor提供了<code>reactor-adapter</code>组件，可以方便的和RxJava的api转换。</p>
<p>其实还有<strong>Vert.x</strong>也算异步框架 (底层使用netty实现nio, 最新版已支持reactive stream规范)</p>
<h2 id="异步化真正的好处">异步化真正的好处</h2>
<h3 id="scalability">Scalability</h3>
<p>伸缩性主要体现在以下两个方面：</p>
<ul>
<li><strong>elastic 弹性</strong></li>
<li><strong>resilient 容错性</strong></li>
</ul>
<p>（异步化在平时<strong>不会明显降低 RT、提高 QPS</strong>，文章开头的数据也是在大促这种流量高峰下的体现出的异步效果）</p>
<p>从架构和应用等更高纬度看待异步带来的好处则会提升系统的两大能力：<strong>弹性</strong> 和 <strong>容错性</strong></p>
<p>前者反映了系统应对压力的表现，后者反映了系统应对故障的表现</p>
<h4 id="1-容错性">1. 容错性</h4>
<p>像RxJava，Reactor这些异步框架处理回调数据时一般会切换线程上下文，其实就是使用不同的线程池来隔离不同的数据流处理逻辑，下图说明了这一特性的好处：</p>
<figure data-type="image" tabindex="15"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/225922.png" alt="img" loading="lazy"></figure>
<p>即利用异步框架支持线程池切换的特性实现<strong>服务/接口隔离</strong>，进而提高系统的<strong>高可用</strong>。</p>
<h4 id="2-弹性">2. 弹性</h4>
<figure data-type="image" tabindex="16"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/134231.png" alt="img" loading="lazy"></figure>
<p>back-pressure是一种重要的反馈机制，相比于传统的熔断限流等方式，是一种更加<strong>柔性的自适应限流</strong>。使得系统得以优雅地响应负载，而不是在负载下崩溃。</p>
<h2 id="异步化落地的难点及解决方案">异步化落地的难点及解决方案</h2>
<p>还是先看下淘宝总结的异步改造中难点问题：</p>
<figure data-type="image" tabindex="17"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/130202.png" alt="img" loading="lazy"></figure>
<p>中间件全异步牵涉到到公司中台化战略或框架部门的支持，包括公司内部常用的中间件比如MQ、redis、dal等。</p>
<p>这里主要说下上下文传递和阻塞检测的问题：</p>
<h3 id="1-上下文传递">1. 上下文传递</h3>
<p>改造成异步服务后，不能再使用<code>ThreadLocal</code>传递上下文context，因为异步框架比如RxJava一般在收到通知后会先调用<code>observeOn()</code>方法切换成另外一个线程处理回调，比如我们在请求接口时在<code>ThreadLocal</code>的context里设置了一个值，在回调线程里从context里取不到这个值的，因为此时已经不是同一个<code>ThreadLocal</code>了，所以需要我们手动在切换上下文的时候传递context从一个线程到另一个线程环境，伪代码如下：</p>
<pre><code>Context context = ThreadLocalUtils.get(); // 获取当前线程的上下文
single.observeOn(scheduler).doOnEvent((data, error) -&gt; ThreadLocalUtils.set(context)); // 切换线程后在doOnEvent里重新给新的线程赋值context
</code></pre>
<p>在<code>observeOn()</code>方法切换成另外一个线程后调用<code>doOnEvent</code>方法将原来的context赋给新的线程<code>ThreadLocal</code></p>
<p><strong>注意</strong>：这里的代码只是提供一种解决思路，实际在使用前和使用后还要考虑清空<code>ThreadLocal</code>，因为线程有可能会回收到线程池下次复用，而不是立即清理，<strong>这样就会污染上下文环境</strong>。</p>
<p>可以将传递上下文的方法封装成公共方法，不需要每次都手动切换。</p>
<h3 id="2-阻塞检测">2. 阻塞检测</h3>
<p>阻塞检测主要是要能及时发现我们某个异步任务长时间阻塞的发生，比如异步线程执行时间过长进而影响整个接口的响应，原来同步场景下我们的日志都是串行记录到ES或Cat上的，现在改成异步后，每次处理接口数据的逻辑可能在不同的线程中完成，这样记录的日志就需要我们主动去合并（依据具体的业务场景而定），如果日志无法关联起来，对我们排查问题会增加很多难度。所幸的是随着异步的流行，现在很多日志和监控系统都已支持异步了。</p>
<p>Project Reactor 自己也有阻塞检测功能</p>
<h3 id="3-其他问题">3. 其他问题</h3>
<p>除了上面提到的两个问题外，还有一些比如RxJava2.0之后不支持返回null，如果我们原来的代码或编程习惯所致返回结果有null的情况，可以考虑使用java8的<code>Optional.ofNullable()</code>包装一下，然后返回的RxJava类型是这样的：<code>Single&lt;Optional&gt;</code>，其他异步框架如果有类似的问题同理。</p>
<h2 id="异步其他解决方案纤程协程">异步其他解决方案：纤程/协程</h2>
<ul>
<li>Quasar</li>
<li>Kilim</li>
<li>Kotlin</li>
<li>Open JDK Loom</li>
<li>AJDK wisp2</li>
</ul>
<p>协程并不是什么新技术，它在很多语言中都有实现，比如 <code>Python</code>、<code>Lua</code>、<code>Go</code> 都支持协程。</p>
<p>协程与线程不同之处在于，<strong>线程由内核调度，而协程的调度是进程自身完成的</strong>。这样就可以不受操作系统对线程数量的限制，一个线程内部可以创建成千上万个协程。因为上文讲到的异步技术都是基于线程的操作和封装，Java中的线程概念对应的就是操作系统的线程。</p>
<h3 id="1-quasar-kilim">1. Quasar、Kilim</h3>
<p>开源的Java轻量级线程（协程）框架，通过利用<code>Java instrument</code>技术对字节码进行修改，使方法挂起前后可以保存和恢复JVM栈帧，方法内部已执行到的字节码位置也通过增加状态机的方式记录，在下次恢复执行可直接跳转至最新位置。</p>
<h3 id="2-kotlin">2. Kotlin</h3>
<p>Kotlin Coroutine 协程库，因为 Kotlin 的运行依赖于 JVM，不能对 JVM  进行修改，因此Kotlin不能在底层支持协程。同时Kotlin 是一门编程语言，需要在语言层面支持协程，所以Kotlin  对协程支持最核心的部分是在编译器中完成，这一点其实和Quasar、Kilim实现原理类似，都是在<strong>编译期通过修改字节码</strong>的方式实现协程</p>
<h3 id="3-project-loom">3. Project Loom</h3>
<p>Project Loom 发起的原因是因为长期以来Java 的线程是与操作系统的线程一一对应的，这限制了 Java 平台并发能力提升，Project Loom 是<strong>从 JVM 层面对多线程技术进行彻底的改变</strong>。</p>
<p>OpenJDK 在2018年创建了 Loom 项目，目标是在JVM上实现轻量级的线程，并解除JVM线程与内核线程的映射。其实 Loom  项目的核心开发人员正是从Quasar项目过来的，目的也很明确，就是要将这项技术集成到底层JVM里，所以Quasar项目目前已经不维护了。。。</p>
<h3 id="4-ajdk-wisp2">4. AJDK Wisp2</h3>
<p>Alibaba Dragonwell 是阿里巴巴的 Open JDK 发行版，提供长期支持。dragonwell8已开源协程功能（之前的版本是不支持的），开启jvm命令：<code>-XX:+UseWisp2</code> 即支持协程。</p>
<h2 id="总结">总结</h2>
<ul>
<li>Future 在异步方面支持有限</li>
<li>Callback 在编排能力方面有 Callback Hell 的短板</li>
<li>Project Loom 最新支持的Open JDK版本是16，目前还在测试中</li>
<li>AJDK wisp2 需要换掉整个JVM，需要考虑改动成本和收益比</li>
</ul>
<p>所以目前实现异步化比较成熟的方案是 <strong>Reactive Streams</strong></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[解析springcloud分布式微服务的实现]]></title>
        <id>https://kangjn.github.io/post/jie-xi-springcloud-fen-bu-shi-wei-fu-wu-de-shi-xian/</id>
        <link href="https://kangjn.github.io/post/jie-xi-springcloud-fen-bu-shi-wei-fu-wu-de-shi-xian/">
        </link>
        <updated>2021-04-21T05:59:47.000Z</updated>
        <content type="html"><![CDATA[<h2 id="分布式系统">分布式系统</h2>
<p>微服务就是原来臃肿的项目拆分为多个模块互不关联。如：按照子服务拆分、数据库、接口，依次往下就更加细粒度，当然运维也就越来越难受了。</p>
<p>分布式则是偏向与机器将诺大的系统划分为多个模块部署在不同服务器上。</p>
<p>微服务和分布式就是作用的“目标不一样”。</p>
<h2 id="微服务与cloud">微服务与Cloud</h2>
<p>微服务是一种概念，spring-cloud是微服务的实现。</p>
<p>微服务也不一定必须使用cloud来实现，只是微服务中有许多问题，如：负载均衡、服务注册与发现、路由等等。</p>
<p>而cloud则是将这些处理问题的技术整合了。</p>
<h2 id="spring-cloud-组件">Spring-Cloud 组件</h2>
<p><strong>Eureka</strong></p>
<p>Eureka是Netifix的子模块之一，Eureka有2个组件，一个EurekaServer 实现中间层服务器的负载均衡和故障转移，一个EurekaClient它使得与server交互变得简单。</p>
<p>Spring-Cloud封装了Netifix公司开发的Eureka模块来实现服务注册和发现。</p>
<p>通过Eureka的客户端 Eureka Server维持心跳连接，维护可以更方便监控各个微服务的运行。</p>
<p><strong>角色关系图</strong></p>
<figure data-type="image" tabindex="1"><img src="https://gitee.com/kangjun/MyBlogImage/raw/master/720w.jpeg" alt="img" loading="lazy"></figure>
<p><strong>Eureka使用</strong></p>
<p>客户端</p>
<pre><code>&lt;dependency&gt;
&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
&lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;
&lt;/dependency&gt;
server:
port: 4001
eureka:
client:
serviceUrl:
defaultZone: http://localhost:3000/eureka/ #eureka服务端提供的注册地址 参考服务端配置的这个路径
instance:
instance-id: admin-1 #此实例注册到eureka服务端的唯一的实例ID
prefer-ip-address: true #是否显示IP地址
leaseRenewalIntervalInSeconds: 10 #eureka客户需要多长时间发送心跳给eureka服务器，表明它仍然活着,默认为30 秒 (与下面配置的单位都是秒)
leaseExpirationDurationInSeconds: 30 #Eureka服务器在接收到实例的最后一次发出的心跳后，需要等待多久才可以将此实例删除，默认为90秒

spring:
application:
name: server-admin #此实例注册到eureka服务端的name
</code></pre>
<p>服务端</p>
<pre><code>&lt;dependency&gt;
&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
&lt;artifactId&gt;spring-cloud-starter-
netflix-eureka-server&lt;/artifactId&gt;
&lt;/dependency&gt;
yml文件声明 
server:
port: 3000
eureka:
server:
enable-self-preservation: false #关闭自我保护机制
eviction-interval-timer-in-ms: 4000 #设置清理间隔
（单位：毫秒 默认是60*1000）
instance:
hostname: localhost 
client:
registerWithEureka: false #不把自己作为一个客户端注册到自己身上
fetchRegistry: false #不需要从服务端获取注册信息
（因为在这里自己就是服务端，而且已经禁用自己注册了）
serviceUrl:
defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka
在SpringBoot 启动项目中加入注解:@EnableEurekaServer 
就可以启动项目了，访问对应地址就可以看到界面。
</code></pre>
<p><strong>Eureka 集群</strong></p>
<p>服务启动后Eureka Server会向其他服务server 同步，当消费者要调用服务提供者，则向服务注册中心获取服务提供者的地址，然后将提供者的地址缓存到本地，下次调用时候直接从本地缓存中获取</p>
<p>yml 服务端</p>
<pre><code>server:
port: 3000
eureka:
server:
enable-self-preservation: false #关闭自我保护机制
eviction-interval-timer-in-ms: 4000 #设置清理间隔
（单位：毫秒 默认是60*1000）
instance:
hostname: eureka3000.com 
client:
registerWithEureka: false #不把自己作为一个客户端
注册到自己身上
fetchRegistry: false #不需要从服务端获取注册信息
（因为在这里自己就是服务端，而且已经禁用自己注册了）
serviceUrl:
defaultZone: http://eureka3001.com:3001/eureka,
http://eureka3002.com:3002/eureka
(这里不注册自己，注册到其他服务上面以为会同步。)
</code></pre>
<p><strong>yml 客户端</strong></p>
<pre><code>server:
port: 4001
eureka:
client:
serviceUrl:
defaultZone:http://localhost:3000/eureka/,http://
eureka3001.com:3001/eureka,http://eureka3002.com:3 002
/eureka #eureka服务端提供的注册地址 参考服务端配置的这个路径
instance:
instance-id: admin-1 #此实例注册到eureka服务端的唯一的实例ID
prefer-ip-address: true #是否显示IP地址
leaseRenewalIntervalInSeconds: 10 #eureka客户需要多长时间发
送心跳给eureka服务器，表明它仍然活着,默认为30 秒 (与下面配置的单位都是秒)
leaseExpirationDurationInSeconds: 30 #Eureka服务器在
接收到实例的最后一次发出的心跳后，需要等待多久才可以将此实例删除，默认为90秒

spring:
application:
name: server-admin #此实例注册到eureka服务端的name
</code></pre>
<p><strong>CAP定理</strong></p>
<pre><code>C：Consistency 一致性
A：Availability 可用性
P：Partition tolerance 分区容错性
这三个指标不能同时达到
</code></pre>
<p><strong>Partition tolerance</strong></p>
<p>分区容错性，大多数分布式系统都部署在多个子网络。每一个网络是一个区。区间的通信是可能失败的如一个在本地，一个在外地，他们之间是无法通信的。分布式系统在设计的时候必须要考虑这种情况。</p>
<p><strong>Consistency</strong></p>
<p>一致性，写操作后的读取，必须返回该值。如：服务器A1和服务器A2，现在发起操作将A1中V0改为V1，用户去读取的时候读到服务器A1得到V1，如果读到A2服务器但是服务器</p>
<p>还是V0，读到的数据就不对，这就不满足一致性。</p>
<p>所以让A2返回的数据也对，的让A1给A2发送一条消息，把A2的V0变为V1，这时候不管从哪里读取都是修改后的数据。</p>
<p><strong>Availability</strong></p>
<p>可用性就是用户只要给出请求就必须回应，不管是本地服务器还是外地服务器只要接收到就必须做出回应，不管数据是否是最新必须做出回应，负责就不是可用性。</p>
<p><strong>C与A矛盾</strong></p>
<p>一致性和可用性不能同时成立，存在分区容错性，通信可能失败。</p>
<p>如果保证一致性，A1在写操作时，A2的读写只能被锁定，只有等数据同步了才能读写，在锁定期间是不能读写的就不符合可用性。</p>
<p>如果保持可用性，那么A2就不会被锁定，所以一致性就不能成立。</p>
<p>综上 无法做到一致性和可用性，所以系统在设计的时候就只能选其一。</p>
<p><strong>Eureka与Zookeeper</strong></p>
<p>Zookeeper遵循的是CP原则保持了一致性，所以在master节点因为网络故障与剩余“跟随者”接点失去联系时会重新选举“领导者”，选取“领导者”大概会持续30-120s的时间，且选举的时候整个zookeeper是不可用的。导致在选举的时候注册服务瘫痪。</p>
<p>Eureka在设计的时候遵循AP可用性。Eureka各个接点是公平的，没有主从之分，down掉几个几点也没问题，其他接点依然可以支持注册，只要有一台Eureka在，注册就可以用，只不过查询到的数据可能不是最新的。Eureka有自我保护机制，如果15分钟之内超过85%接点都没有正常心跳，那么Eureka认为客户端与注册中心出现故障，此时情况可能是</p>
<p>Eureka不在从注册列表移除因为长时间没有瘦到心跳而过期的服务。</p>
<p>Eureka仍然能够接收注册和查询，但不会同步到其他接点。</p>
<p>当网络稳定后，当前的 实例注册信息会更新到其他接点。</p>
<p><strong>Ｒibbon</strong></p>
<p>rebbon主要提供客户端的负载均衡，提供了一套完善的客户端的配置。Rebbin会自动帮助你基于某种规则（如：简单的轮询，随机链接等）。</p>
<p>服务端的负载均衡是一个url通过一个代理服务器，然后通过代理服务器（策略：轮询，随机 ，权重等等），反向代理到你的服务器。</p>
<p>客户端负载均衡是通过一个请求在客户端已经声明了要调用那个服务，然后通过具体算法来完成负载均衡。</p>
<p><strong>Ｒibbon使用</strong></p>
<p>引入依赖，Eureka以及把Ribbon集成在里面。</p>
<p>使用Ribbon只有在RestTemplate上面加入@LoadBalanced注解。</p>
<p><strong>Feign负载均衡</strong></p>
<p>feign是一个声明式的webService客户端，使用feign会让编写webService更简单，就是定义一个接口加上注解。</p>
<p>feign是为了编写java http客户端更加简单，在Ribbon+RestTemplate此基础上进一步封装，简化了使用Spring Cloud Ribbon时，自动封装服务调用客户端的开发量。</p>
<p><strong>Feign使用</strong></p>
<pre><code>引入依赖
&lt;dependency&gt;
&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
&lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;
&lt;/dependency&gt;
在启动类上加@EnableFeignClients
然后在接口上加@FeignClient(&quot;SERVER-POWER&quot;)注解其中参数就是服务的名字。
</code></pre>
<p><strong>Feign集成Ribbon</strong></p>
<p>利用Ribbon维护服务列表信息，融合了Ribbon的负载均衡配置，与Ribbon不同的是Feign只需要定义服务绑定接口以声明的方式，实现简答的服务调用。</p>
<h2 id="hystrix断路器">hystrix断路器</h2>
<p>是一种用于处理分布式系统延迟和容错的开源库。在分布式系统中许多依赖不可避免的会调用失败，比如超时、异常等，断路器保证出错不会导致整体服务失败，避免级联故障。</p>
<p>断路器其实就是一种开关设置，类似保险丝，像调用方返回一个符合预期的、可处理的备选响应，而不是长时间等待或者抛出无法处理的异常，保证服务调用方线程不会被长时间 不必要占用，从而避免了在分布式系统中蔓延，乃至雪崩。</p>
<p>微服务中 client-&gt;微服务A-&gt;微服务B-&gt;微服务C-&gt;微服务D,其中微服务B异常了，所有请求微服务A的请求都会卡在B这里，就会导致线程一直累积在这里，那么其他微服务就没有可用线程，导致整个服务器雪崩。</p>
<p>针对这方案有 服务限流、超时监控、服务熔断、服务降级</p>
<p><strong>降级 超时</strong></p>
<p>降级就是服务响应过长 ，或者不可用了，就是服务调用不了了，我们不能把错误信息返回出来，或者长时间卡在哪里，所以要准备一个策略当发生这种问题我们直接调用这个方法快速返回这个请求，不让他一直卡在那。</p>
<p>要在调用方做降级（要不然那个微服务都down掉了在做降级就没有意义）。</p>
<p>引入hystrix依赖</p>
<pre><code>&lt;dependency&gt; 
&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
&lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; 
&lt;/dependency&gt;
在启动类上加入@EnableHystrix 或者@EnableCircuitBreaker。
@RequestMapping(&quot;/feignPower.do&quot;) 
@HystrixCommand(fallbackMethod = &quot;fallbackMethod&quot;) 
public Object feignPower(String name){ 
return powerServiceClient.power(); 
} 
fallbackMethod：
public Object fallbackMethod(String name){ 
System.out.println(name); 
return R.error(&quot;降级信息&quot;); 
}
这里的降级信息具体内容根据业务需求来，比如返回一个默认的查询信息等等。
hystrix有超时监听，当你请求超过1秒 就会超时，这个是可以配置的
</code></pre>
<p>这里的降级信息具体内容根据业务需求来，比如返回一个默认的查询信息等等。</p>
<p>hystrix有超时监听，当你请求超过1秒 就会超时，这个是可以配置的</p>
<p><strong>降级什么用</strong></p>
<p>第一他可以监听服务有没有超时。第二报错了他这里直接截断了没有让请求一直卡在这个。</p>
<p>其实降级，当你系统迎来高并发的时候，这时候发现系统马上承载不了这个大的并发 ，可以先关闭一些不重要 的微服务（就是在降级方法返回一个比较友好的信息）把资源让出来给主服务，其实就是整体资源不够用了，忍痛关闭某些服务，待过渡后再打开。</p>
<p><strong>熔断限流</strong></p>
<p>熔断就像生活中的跳闸，比如电路故障了，为了防止事故扩大，这里切断你的电源以免意外发生。当一个微服务调用多次，hystrix就会采取熔断  机制，不在继续调用你的方法，会默认短路，5秒后试探性的先关闭熔断机制，如果在这时候失败一次会直接调用降级方法，一定程度避免雪崩，</p>
<p>限流，限制某个微服务使用量，如果线程占用超过了，超过的就会直接降级该次调用。</p>
<p><strong>Feign整合hystrix</strong></p>
<pre><code>feign默认支持hystrix，需要在yml配置中打开。
feign: 
hystrix: 
enabled: true

降级方法
@FeignClient(value = &quot;SERVER-POWER&quot;, fallback = PowerServiceFallBack.class)
public interface PowerServiceClient {

@RequestMapping(&quot;/power.do&quot;)
public Object power(@RequestParam(&quot;name&quot;) String name);
}

在feign客户端的注解上 有个属性叫fallback 然后指向一个类 PowerServiceClient 
@Component
public class PowerServiceFallBack implements PowerServiceClient {
@Override
public Object power(String name) {
return R.error(&quot;测试降级&quot;);
}
}
</code></pre>
<h2 id="zuul-网关">Zuul 网关</h2>
<p>zuul包含了对请求的路由和过滤两个主要功能</p>
<p>路由是将外部请求转发到具体的微服务实例上。是实现统一入口基础而过滤器功能负责对请求的处理过程干预，是实现请求校验等功能。</p>
<p>Zuul与Eureka进行整合，将zuul注册在Eureka服务治理下，同时从Eureka获取其他服务信息。（zuul分服务最终还是注册在Eureka上）</p>
<p><strong>路由</strong></p>
<pre><code>&lt;dependency&gt;
&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
&lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;
&lt;/dependency&gt;
dependency&gt;
&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
&lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;
&lt;/dependency&gt;
最后要注册在Eureka上所以需要引入eureka依赖
YML
server:
port: 9000
eureka:
client:
serviceUrl:
defaultZone: http://localhost:3000/eureka/ #eureka服务端提供的注册地址 参考服务端配置的这个路径
instance:
instance-id: zuul-0 #此实例注册到eureka服务端的唯一的实例ID
prefer-ip-address: true #是否显示IP地址
leaseRenewalIntervalInSeconds: 10 #eureka客户需要多长时间发送心跳给eureka服务器，表明它仍然活着,默认为30 秒 (与下面配置的单位都是秒)
leaseExpirationDurationInSeconds: 30 #Eureka服务器在接收到实例的最后一次发出的心跳后，需要等待多久才可以将此实例删除，默认为90秒

spring:
application:
name: zuul #此实例注册到eureka服务端的name 
启动类 @EnableZuulProxy

在实际开发当中我们肯定不会/server-power这样通过微服务调用，
可能只要一个/power就好了 
zuul: 
routes:
mypower: 
serviceId: server-power 
path: /power/** 
myorder: 
serviceId: server-order 
path: /order/**
注意/**代表是所有层级 /* 是代表一层。
一般我们会禁用服务名调用
ignored-services：server-order 这样就不能通过此服务名调用，
不过这个配置如果一个一个通微服务名字设置太复杂
一般禁用服务名 ignored-services：“*”
有时候要考虑到接口调用需要一定的规范，比如调用微服务URL需要前缀/api，可以加上一个prefix
prefix：/api 在加上strip-prefix: false /api前缀是不会出现在路由中
zuul:
prefix: /api
ignored-services: &quot;*&quot;
stripPrefix: false
routes:
product:
serviceId: server-product
path: /product/**
order:
serviceId: server-order
path: /order/**
</code></pre>
<p><strong>过滤器</strong></p>
<p>过滤器(filter)是zuul的核心组件，zuul大部分功能是通过过滤器实现的，zuul中定义了4种标准过滤器类型，这些过滤器类型对应与请求的生命周期，</p>
<p>PRE：这种过滤器在请求路由前被调用，可利用过滤器进行身份验证，记录请求微服务的调试信息等。</p>
<p>ROUTING：这种过滤器将请求路由到微服务，这种过滤器用于构建发送给微服务请求，并使用 Apache HttpClient或Netfix Ribbon请求微服务。</p>
<p>POST：这种过滤器在路由微服务后执行，可用来相应添加标准的HTTP Header、收集统计信息和指标、将响应从微服务发送给客户端。</p>
<p>ERROR：在其他阶段发送错误时执行过滤器</p>
<p><strong>继承ZuulFilter</strong></p>
<pre><code>@Component
public class LogFilter extends ZuulFilter { 
@Override
public String filterType() {
return FilterConstants.PRE_TYPE;
}

@Override
public int filterOrder() {
return FilterConstants.PRE_DECORATION_FILTER_ORDER+1;
}

@Override
public boolean shouldFilter() {
return true;
}

@Override
public Object run() throws ZuulException {
RequestContext ctx = RequestContext.getCurrentContext();
//被代理到的微服务
String proxy = (String)ctx.get(&quot;proxy&quot;);
//请求的地址
String requestURI = (String)ctx.get(&quot;requestURI&quot;);
//zuul路由后的url
System.out.println(proxy+&quot;/&quot;+requestURI);
HttpServletRequest request = ctx.getRequest();
String loginCookie = CookieUtil.getLoginCookie(request);
ctx.addZuulRequestHeader(&quot;login_key&quot;,loginCookie);
return null;
}
}
</code></pre>
<p>由此可知道自定义zuul Filter要实现以下几个方法。</p>
<p>filterType：返回过滤器类型，有pre、route、post、erro等几种取值</p>
<p>filterOrder：返回一个int值指定过滤器的顺序，不同过滤器允许返回相同数字。</p>
<p>shouldFilter：返回一个boolean判断过滤器是否执行，true执行，false不执行。</p>
<p>run：过滤器的具体实现。</p>
<p>Spting-Cloud默认为zuul编写并开启一些过滤器。如果要禁用部分过滤器，只需在application.yml里设置zuul…disable=true，例如zuul.LogFilter.pre.disable=true</p>
<p>zuul也整合了了hystrix和ribbon的， 提供降级回退，继承FallbackProvider 类 然后重写里面的方法。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[深入理解Java8]]></title>
        <id>https://kangjn.github.io/post/shen-ru-li-jie-java8/</id>
        <link href="https://kangjn.github.io/post/shen-ru-li-jie-java8/">
        </link>
        <updated>2021-04-21T03:27:20.000Z</updated>
        <content type="html"><![CDATA[<h3 id="lambda的基本语法">Lambda的基本语法</h3>
<p>(parm1,parm1,parm1) -&gt;{<br>
};</p>
<blockquote>
<p>lambda表达式结构</p>
</blockquote>
<ul>
<li>一个lambda表达式可以有零个或多个参数</li>
<li>参数的类型既可以明确声明，也可以根据上下文来推断</li>
<li>所有参数需包含在圆括号内，参数之间用逗号相隔</li>
<li>空圆括号代表参数集为空</li>
<li>当只有一个参数，且其类型可推导时，圆括号()可省略</li>
<li>Lambda表达式的主体可包含零条或多条语句</li>
<li>如果Lambda表达式的主题只有一条语句，花括号{}可以省略。匿名函数的返回类型与该主体表达式一致</li>
<li>如果Lambda表达式的主题包含一条以上语句，则表达式必须包含再花括号{}中。匿名函数的返回类型与代码块的返回类型一致，若没有则返回为空</li>
</ul>
<blockquote>
<p>函数式接口</p>
</blockquote>
<ul>
<li>一个接口中只有一个抽象的方法</li>
<li>声明函数式接口时，在接口上添加<code>@FunctionalInterface</code>注解，这样编译器会按照函数式接口去验证</li>
<li>一个接口中只有一个抽象方法时，编译器会默认这个接口为函数式接口</li>
<li>接口中定义的方法为定级父类Object类中的方法时，接口可以拥有两个及以上的方法。因为接口的实现类也会继承Object,所以编译器会认为接口中只有一个方法</li>
</ul>
<blockquote>
<p>注意点</p>
</blockquote>
<ul>
<li>在Python、JavaScript等语言中lambda为函数，在java中lambda为对象</li>
<li>在java8中，接口中可以有具体方法的实现，必须是<code>default meathod</code></li>
<li>在java中可以使用静态方法</li>
</ul>
<h3 id="函数式接口如何实例">函数式接口如何实例</h3>
<blockquote>
<p>函数式方法的声明</p>
</blockquote>
<ol>
<li>采用lambda表达式的方式进行声明一个接口实例<br>
package funcationdemo;</li>
</ol>
<p>import java.util.Arrays;<br>
import java.util.List;</p>
<p>/**</p>
<ul>
<li>
<p>描述:</p>
</li>
<li>
<p>lambda表达式练习<br>
*/<br>
public class Test01 {<br>
public static void main(String[] args) {<br>
List<Integer> list = Arrays.asList(1, 2, 3, 4, 5, 7);<br>
MyInterface myInterface = i -&gt; {<br>
return i;<br>
};<br>
list.forEach(i -&gt; System.out.println(myInterface.printElement(i)));</p>
<p>}<br>
}<br>
@FunctionalInterface<br>
interface MyInterface{<br>
Integer printElement(Integer i);<br>
}</p>
</li>
</ul>
<ol>
<li>采用方法引用的方式进行声明<br>
public class Test01 {<br>
public static void main(String[] args) {<br>
List<String> list2 = Arrays.asList(&quot;hello&quot;,&quot;world&quot;,&quot;hello world&quot;);<br>
list2.forEach(String::toUpperCase);<br>
}<br>
}</li>
<li>采用构造方法的方式进行声明<br>
package funcationdemo;</li>
</ol>
<p>/**</p>
<ul>
<li>描述:</li>
<li>lambda表达式练习<br>
*/<br>
public class Test01 {<br>
public static void main(String[] args) {<br>
MyInterface myInterface = Person::new;<br>
System.out.println(myInterface.getPerson(&quot;李华&quot;));<br>
}<br>
}</li>
</ul>
<p>@FunctionalInterface<br>
interface MyInterface {<br>
Person getPerson(String name);<br>
}</p>
<p>class Person {<br>
private String name;</p>
<pre><code>public Person(String name) {
    this.name = name;
}

public String getName() {
    return name;
}

public void setName(String name) {
    this.name = name;
}

@Override
public String toString() {
    return &quot;Person{&quot; +
        &quot;name='&quot; + name + '\'' +
        '}';
}
</code></pre>
<p>}</p>
<h3 id="函数式接口四种类型">函数式接口四种类型</h3>
<p>函数式接口	方法	参数类型	返回类型	作用<br>
Consumer消费型接口	void accept(T t)	T	void	对T类型的参数进行操作<br>
Supplier供给型接口	T get()	无	T	操作数据，返回T类型的结果<br>
Function函数型接口	R apply(T t)	T	R	对T类型参数进行操作，并返回R类型的结果<br>
Predicate 断定型接口	boolean test(T t)	T	boolean	确定T类型参数是否满足某约束，并返回boolean值</p>
<h3 id="lambda表达式的作用">Lambda表达式的作用</h3>
<ul>
<li>传递行为，而不仅仅是值</li>
<li>提升抽象层次</li>
<li>API重用性更好</li>
<li>更加灵活</li>
</ul>
<h3 id="function接口">Function接口</h3>
<blockquote>
<p><strong>函数式接口中，可以进行传值，也可以进行行为的传递，可以让方法的使用者传递方法所需要实现的行为，方法本身做更加抽象的逻辑实现</strong><br>
package funcationdemo;</p>
</blockquote>
<p>import java.util.function.Function;</p>
<p>/**</p>
<ul>
<li>
<p>描述:</p>
</li>
<li>
<p>function 函数实现*<br>
*/<br>
public class FunctionTest {<br>
public static void main(String[] args) {<br>
FunctionTest functionTest = new FunctionTest();<br>
System.out.println(functionTest.compute(3, value -&gt; value * value));<br>
}</p>
<p>public int compute(int a, Function&lt;Integer, Integer&gt; function) {<br>
return function.apply(a);<br>
}<br>
}</p>
</li>
</ul>
<h4 id="bifunction接口">BiFunction接口</h4>
<p>package funcationdemo;</p>
<p>import java.util.function.BiFunction;<br>
import java.util.function.Function;</p>
<p>/****************************************</p>
<ul>
<li>描述:</li>
<li>BiFunction函数接口练习</li>
<li>Interface BiFunction&lt;T,U,R&gt;</li>
<li>
<pre><code> T - 函数的第一个参数类型
</code></pre>
</li>
<li>
<pre><code> U - 函数的第二个参数类型
</code></pre>
</li>
<li>
<pre><code> R - 函数结果的类型
</code></pre>
</li>
<li></li>
<li>
<pre><code> 表示接受两个参数并产生结果的函数。
</code></pre>
</li>
<li>
<pre><code> 是Function函数有两个参数的展现方式
</code></pre>
</li>
<li></li>
</ul>
<p>****************************************/<br>
public class BiFunctionTest {<br>
public static void main(String[] args) {<br>
BiFunctionTest test = new BiFunctionTest();<br>
//        求两个数之和<br>
System.out.println(test.compute(3, 4, Integer::sum));</p>
<p>//        System.out.println(test.compute2(3, 4, Integer::sum, item -&gt; item * item));<br>
//        等价于<br>
System.out.println(test.compute2(3, 4, (num1, num2) -&gt; num1 * num2, value -&gt; value * value));</p>
<pre><code>}

/**
 * public interface BiFunction&lt;T, U, R&gt; {
 * &lt;p&gt;
 * R apply(T t, U u);
 * &lt;p&gt;
 * &lt;p&gt;
 * }
 */
public int compute(int num1, int num2, BiFunction&lt;Integer, Integer, Integer&gt; function) {
    return function.apply(num1, num2);
}


/****
 *  default &lt;V&gt; BiFunction&lt;T, U, V&gt; andThen(Function&lt;? super R, ? extends V&gt; after) {
 *         Objects.requireNonNull(after);
 *         return (T t, U u) -&gt; after.apply(apply(t, u));
 *     }
 * @param num1 计算的值
 * @param num2 计算的值
 * @param function 需要求和函数参数（函数参数指的是需要函数执行的行为）
 * @param function2 需要返回函数参数
 * @return 计算后返回的值
 */
public int compute2(int num1, int num2,
                    BiFunction&lt;Integer, Integer, Integer&gt; function,
                    Function&lt;Integer, Integer&gt; function2) {
    return function.andThen(function2).apply(num1, num2);
}
</code></pre>
<p>}</p>
<h4 id="binaryoperator接口">BinaryOperator接口</h4>
<p>package funcationdemo;</p>
<p>import java.util.Comparator;<br>
import java.util.function.BinaryOperator;</p>
<p>/**************************************************************</p>
<ul>
<li>描述:</li>
<li>BinaryOperator</li>
<li>表示对同一类型的两个操作数的操作，产生与操作数相同的结果。</li>
<li>对于操作数和结果都是相同类型的情况</li>
<li>是BiFunction的专业化</li>
<li></li>
</ul>
<p>**************************************************************/<br>
public class BinaryOperatorTest {<br>
public static void main(String[] args) {<br>
BinaryOperatorTest test = new BinaryOperatorTest();<br>
System.out.println(test.compute(3, 4, Integer::sum));<br>
System.out.println(test.minByComparator(5, 6, Comparator.comparingInt(num -&gt; num)));<br>
}</p>
<pre><code>/****
 *
 * 继承 BiFunction&lt;T,T,T&gt; ,也拥有 apply()方法
 * 三个参数必须是同类型的
 *
 * public interface BinaryOperator&lt;T&gt; extends BiFunction&lt;T,T,T&gt; {
 *
 * }
 *
 *
 * @param num1
 * @param num2
 * @param function
 * @return
 */
public int compute(int num1, int num2, BinaryOperator&lt;Integer&gt; function) {
    return function.apply(num1, num2);
}

/***
 *
 *     public static &lt;T&gt; BinaryOperator&lt;T&gt; minBy(Comparator&lt;? super T&gt; comparator) {
 *         Objects.requireNonNull(comparator);
 *         return (a, b) -&gt; comparator.compare(a, b) &lt;= 0 ? a : b;
 *     }
 *
 * @param num1 比较参数1
 * @param num2 比较数字2
 * @param comparator 比较器
 * @return 返回比较的结果
 */

public int minByComparator(int num1, int num2, Comparator&lt;Integer&gt; comparator) {
    return BinaryOperator.minBy(comparator).apply(num1, num2);
}
</code></pre>
<p>}</p>
<h3 id="consumer接口">Consumer接口</h3>
<p>package funcationdemo;</p>
<p>import java.util.Arrays;<br>
import java.util.List;<br>
import java.util.Optional;<br>
import java.util.function.Consumer;</p>
<p>/*********************************************************</p>
<ul>
<li>描述:</li>
<li>Consumer函数</li>
<li>表示接受单个输入参数并且不返回结果的操作</li>
<li></li>
</ul>
<p>********************************************************/<br>
public class ConsumerTest {<br>
public static void main(String[] args) {<br>
List<String> list = Arrays.asList(&quot;hello&quot;, &quot;world&quot;, &quot;hello world&quot;);<br>
list.forEach(str-&gt;{<br>
String strParam = str;<br>
Optional<String> optional = Optional.ofNullable(strParam);<br>
String rtn = optional.map(strParam1 -&gt; strParam1.toUpperCase()).orElse(&quot;&quot;);<br>
System.out.println(rtn);<br>
});</p>
<pre><code>}
</code></pre>
<p>}</p>
<h3 id="predicate接口">Predicate接口</h3>
<h4 id="结合stream流使用">结合Stream流使用</h4>
<p>package funcationdemo;</p>
<p>import java.util.Arrays;<br>
import java.util.List;<br>
import java.util.Optional;<br>
import java.util.function.Consumer;<br>
import java.util.function.Function;<br>
import java.util.function.Predicate;</p>
<p>/**************************************************************</p>
<ul>
<li>描述:</li>
<li>Predicate</li>
<li>
<pre><code> 表示一个参数的谓词
</code></pre>
</li>
<li></li>
</ul>
<p>**************************************************************/<br>
public class PredicateTest {<br>
public static void main(String[] args) {<br>
PredicateTest test = new PredicateTest();<br>
System.out.println(test.isTrueOfStr(&quot;hell0&quot;, str -&gt; str.length() &gt; 4));<br>
List<Integer> list = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9, 10);<br>
//      Predicate 接口使用<br>
Predicate<Integer> predicate = i -&gt; i % 2 == 0;<br>
//       Optional 使用的函数<br>
Function&lt;Integer, Integer&gt; function = integer -&gt; {<br>
Optional<Integer> integerOptional = Optional.of(integer);<br>
Integer rtn = integerOptional.map(ele -&gt; 2 * ele).get();<br>
return rtn;<br>
};<br>
//      输出参数<br>
Consumer<Integer> consumer = param -&gt; {<br>
Optional<Integer> integer = Optional.ofNullable(param);<br>
Integer rtn = integer.map(function).get();<br>
System.out.println(rtn);<br>
};<br>
test.conditionFilter(list, predicate, consumer);<br>
}</p>
<pre><code>public boolean isTrueOfStr(String str, Predicate&lt;String&gt; funciton) {
    return funciton.test(str);
}

public void conditionFilter(List&lt;Integer&gt; list, Predicate&lt;Integer&gt; predicate, Consumer&lt;Integer&gt; consumer) {
    list.stream().filter(predicate).forEach(consumer);
}
</code></pre>
<p>}</p>
<h3 id="supplier接口">Supplier接口</h3>
<p>package funcationdemo;</p>
<p>import java.util.function.Supplier;</p>
<p>/**************************************************************</p>
<ul>
<li>描述:</li>
<li>Supplier</li>
<li>代表结果供应商，没有要求每次调用供应商时都会返回新的或不同的结果</li>
<li>不接受参数，返回一个结果。泛型就是需要返回结果的类型</li>
<li></li>
</ul>
<p>**************************************************************/<br>
public class SupplierTest {<br>
public static void main(String[] args) {<br>
Supplier<String> supplier = String::new;<br>
String str = supplier.get();<br>
str = &quot;hello world&quot;;<br>
System.out.println(str);<br>
}<br>
}</p>
<h3 id="methodreference">MethodReference</h3>
<blockquote>
<p><strong>方法引用是用来直接访问类或者实例的已经存在的方法或者构造方法。<code>方法引用提供了一种引用而不执行方法的方式</code>，它需要由兼容的函数式接口构成的目标类型上下文。计算时，方法引用会创建函数式接口的一个实例。</strong></p>
</blockquote>
<h4 id="引用静态方法containingclassstaticmethodname">引用静态方法：ContainingClass::staticMethodName</h4>
<p>package methodreference;</p>
<p>import java.util.Arrays;<br>
import java.util.List;</p>
<p>/**************************************************************</p>
<ul>
<li>描述:</li>
<li>MethodReference</li>
<li>方法引用</li>
<li></li>
</ul>
<p>**************************************************************/<br>
public class MethodReferenceTest {</p>
<pre><code>static void toUpperCaseByStr(String str) {
    System.out.println(str.toUpperCase());
}

public static void main(String[] args) {
    List&lt;String&gt; list = Arrays.asList(&quot;hello&quot;, &quot;world&quot;, &quot;hello world&quot;);
</code></pre>
<p>//        ContainingClass::staticMethodName 引用静态方法<br>
list.forEach(MethodReferenceTest::toUpperCaseByStr);<br>
}<br>
}</p>
<h4 id="引用某个对象的实例方法containingobjectinstancemethodname">引用某个对象的实例方法：containingObject::instanceMethodName</h4>
<p>package methodreference;</p>
<p>import java.util.Arrays;<br>
import java.util.List;</p>
<p>/**************************************************************</p>
<ul>
<li>描述:</li>
<li>MethodReference</li>
<li>方法引用</li>
<li></li>
</ul>
<p>**************************************************************/<br>
public class MethodReferenceTest {</p>
<pre><code>void toUpperCaseByStr(String str) {
    System.out.println(str.toUpperCase());
}

public static void main(String[] args) {
    List&lt;String&gt; list = Arrays.asList(&quot;hello&quot;, &quot;world&quot;, &quot;hello world&quot;);
    //      引用某个对象的实例方法
    MethodReferenceTest test = new MethodReferenceTest();
    list.forEach(test::toUpperCaseByStr);
}
</code></pre>
<p>}</p>
<h4 id="引用某个类型的任意对象的实例方法containingtypemethodname">引用某个类型的任意对象的实例方法：ContainingType::methodName</h4>
<p>package methodreference;</p>
<p>import java.util.Arrays;<br>
import java.util.List;<br>
import java.util.function.Consumer;</p>
<p>/**************************************************************</p>
<ul>
<li>描述:</li>
<li>MethodReference</li>
<li>方法引用</li>
<li></li>
</ul>
<p>**************************************************************/<br>
public class MethodReferenceTest{</p>
<pre><code>public static void main(String[] args) {
    /*引用某个类型的任意对象的实例方法*/
    List&lt;String&gt; list = Arrays.asList(&quot;hello&quot;, &quot;world&quot;, &quot;hello world&quot;);
    list.sort(String::compareTo);
    list.forEach(System.out::println);
}
</code></pre>
<p>}</p>
<h4 id="引用构造方法classnamenew">引用构造方法：ClassName::new</h4>
<pre><code>package methodreference;

import java.util.function.Supplier;

/**************************************************************
 * 描述:
 *    MethodReference
 *    方法引用
 *
 **************************************************************/
public class MethodReferenceTest{

    public MethodReferenceTest() {
    }

    public String getString(Supplier&lt;String&gt; supplier){
        return supplier.get() +&quot;test&quot;;
    }
    public static void main(String[] args) {
        MethodReferenceTest test = new MethodReferenceTest();
        System.out.println(test.getString(String::new));
    }
}
</code></pre>
<h4 id="超类上的实例方法引用">超类上的实例方法引用</h4>
<p>**组成语法格式：super::methodName</p>
<p>方法的名称由methodName指定，通过使用<strong>super</strong>，可以引用方法的超类版本。</p>
<p>还可以捕获this 指针，this :: equals 等价于lambda表达式 x -&gt; this.equals(x);</p>
<h4 id="数组构造方法引用">数组构造方法引用</h4>
<p>**组成语法格式：TypeName[]::new</p>
<p>例子：</p>
<p>int[]::new 是一个含有一个参数的构造器引用，这个参数就是数组的长度。等价于lambda表达式 x -&gt; new int[x]。</p>
<p>假想存在一个接收int参数的数组构造方法</p>
<p>IntFunction arrayMaker =int[]::new;int[] array = arrayMaker.apply(10)// 创建数组 int[10]</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Docker 教程（三）：Docker 命令]]></title>
        <id>https://kangjn.github.io/post/docker-jiao-cheng-san-docker-ming-ling/</id>
        <link href="https://kangjn.github.io/post/docker-jiao-cheng-san-docker-ming-ling/">
        </link>
        <updated>2021-04-21T03:10:11.000Z</updated>
        <content type="html"><![CDATA[<p>我们通过 Docker 命令与操作 Docker 服务，可以构建 Docker 镜像、运行 Docker 容器、将 Docker 镜像推送到远程等。本文主要介绍一些常用的 Docker 命令。</p>
<p>请注意，根据在 Linux 系统上安装 Docker 的方式，可能需要在所有命令前面加上sudo，使用 root 权限运行他们。比如：</p>
<p>sudo docker build .</p>
<p>… 而不仅仅是：</p>
<p>docker build .</p>
<p>Docker 命令行工具</p>
<p>在 Linux 系统中安装 Docker 时，会安装一个名为docker的命令行工具，可以在 Linux 命令行执行。</p>
<p>docker有很多的参数，不同的参数作用不同，可以指挥 Docker 做出不同的行为，可以认为是给 Docker 的命令。以下是docker命令示例：</p>
<p>docker build .</p>
<p>这个示例中包含三部分：docker命令、参数build、参数.。</p>
<p>参数build是一个 Docker 命令，换句话说，是一个给 docker 可执行命令行的命令。通常，docker 命令行的第一个参数都是 Docker 命令。</p>
<p>参数.是build命令的参数。<br>
docker build</p>
<p>docker build命令是调用 Docker 从 Dockerfile 文件构建 docker 镜像，要使用docker build命令，必须告诉它从哪个 Dockerfile 文件生成镜像。关于 Dockerfile 的内容，可以查看 这里。以下是docker build命令示例：</p>
<p>docker build .</p>
<p>参数.表示从当前目录找到 Dockerfile 文件。<br>
docker images</p>
<p>docker images命令是列出本机的 Docker 镜像，以下是docker images命令示例：</p>
<p>docker images</p>
<p>运行上述命令会输出类似下面的内容：</p>
<p>REPOSITORY       TAG        IMAGE ID        CREATED          SIZE<br>
hello-world      latest     fce289e99eb9    9 months ago     1.84kB</p>
<p>docker run</p>
<p>docker run命令用来基于给定的 Docker 镜像运行 Docker 容器，docker run的参数，可以是 Docker 镜像的名称或 ID，以下是运行 Docker 容器的示例：</p>
<p>docker run hello-world</p>
<p>这个例子会基于hello-world镜像运行 Docker 容器。</p>
<p>我们还可以通过 Docker 镜像 ID 运行 Docker 容器，命令如下：</p>
<p>docker run fce289e99eb9</p>
<p>docker ps</p>
<p>docker ps命令用于显示当前系统中正在运行的 Docker 容器，示例如下：</p>
<p>docker ps</p>
<p>注意，一些 Docker 容器会在完成任务后立即关闭，在docker ps的结果列表中，这种 Docker 容器很有可能会很长时间都不可见。</p>
]]></content>
    </entry>
</feed>